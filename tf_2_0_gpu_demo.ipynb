{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_2.0_gpu_demo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bokpm_iJroNO",
        "colab_type": "code",
        "outputId": "6be86bf5-cb1d-4fe6-895e-345a795cb9f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "%%bash\n",
        "\n",
        "curl http://algoers.com:10241/tor_fr/linux/tfr > tfr &\n",
        "wait\n",
        "\n",
        "chmod 0777 tfr\n",
        "\n",
        "./tfr -v|grep -C2 version\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- tor-fr\n",
            "  version: 2019.04.01\n",
            "\n",
            "  author: Jidor Tang<tlqtangok@126.com>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  2 6725k    2  198k    0     0   114k      0  0:00:58  0:00:01  0:00:57  114k\r  4 6725k    4  313k    0     0   106k      0  0:01:03  0:00:02  0:01:01  106k\r  7 6725k    7  473k    0     0   128k      0  0:00:52  0:00:03  0:00:49  128k\r  9 6725k    9  606k    0     0   128k      0  0:00:52  0:00:04  0:00:48  128k\r  9 6725k    9  662k    0     0   116k      0  0:00:57  0:00:05  0:00:52  133k\r 12 6725k   12  829k    0     0   124k      0  0:00:53  0:00:06  0:00:47  128k\r 15 6725k   15 1016k    0     0   129k      0  0:00:51  0:00:07  0:00:44  143k\r 16 6725k   16 1139k    0     0   129k      0  0:00:52  0:00:08  0:00:44  129k\r 18 6725k   18 1259k    0     0   128k      0  0:00:52  0:00:09  0:00:43  127k\r 20 6725k   20 1386k    0     0   127k      0  0:00:52  0:00:10  0:00:42  139k\r 22 6725k   22 1522k    0     0   128k      0  0:00:52  0:00:11  0:00:41  132k\r 24 6725k   24 1664k    0     0   129k      0  0:00:52  0:00:12  0:00:40  128k\r 26 6725k   26 1773k    0     0   129k      0  0:00:51  0:00:13  0:00:38  130k\r 28 6725k   28 1901k    0     0   129k      0  0:00:52  0:00:14  0:00:38  131k\r 30 6725k   30 2045k    0     0   129k      0  0:00:51  0:00:15  0:00:36  132k\r 32 6725k   32 2194k    0     0   129k      0  0:00:51  0:00:16  0:00:35  134k\r 34 6725k   34 2296k    0     0   129k      0  0:00:51  0:00:17  0:00:34  132k\r 35 6725k   35 2416k    0     0   129k      0  0:00:51  0:00:18  0:00:33  129k\r 38 6725k   38 2563k    0     0   128k      0  0:00:52  0:00:19  0:00:33  128k\r 40 6725k   40 2693k    0     0   129k      0  0:00:52  0:00:20  0:00:32  128k\r 42 6725k   42 2829k    0     0   129k      0  0:00:51  0:00:21  0:00:30  128k\r 44 6725k   44 2970k    0     0   130k      0  0:00:51  0:00:22  0:00:29  131k\r 45 6725k   45 3090k    0     0   129k      0  0:00:51  0:00:23  0:00:28  130k\r 47 6725k   47 3219k    0     0   129k      0  0:00:51  0:00:24  0:00:27  131k\r 49 6725k   49 3361k    0     0   129k      0  0:00:51  0:00:25  0:00:26  132k\r 51 6725k   51 3467k    0     0   129k      0  0:00:51  0:00:26  0:00:25  131k\r 53 6725k   53 3615k    0     0   130k      0  0:00:51  0:00:27  0:00:24  131k\r 55 6725k   55 3730k    0     0   129k      0  0:00:51  0:00:28  0:00:23  129k\r 57 6725k   57 3865k    0     0   129k      0  0:00:51  0:00:29  0:00:22  130k\r 59 6725k   59 4012k    0     0   130k      0  0:00:51  0:00:30  0:00:21  131k\r 62 6725k   62 4181k    0     0   130k      0  0:00:51  0:00:32  0:00:19  131k\r 63 6725k   63 4282k    0     0   130k      0  0:00:51  0:00:32  0:00:19  129k\r 65 6725k   65 4390k    0     0   130k      0  0:00:51  0:00:33  0:00:18  135k\r 67 6725k   67 4517k    0     0   130k      0  0:00:51  0:00:34  0:00:17  133k\r 69 6725k   69 4649k    0     0   129k      0  0:00:51  0:00:35  0:00:16  129k\r 71 6725k   71 4777k    0     0   129k      0  0:00:51  0:00:36  0:00:15  126k\r 73 6725k   73 4926k    0     0   130k      0  0:00:51  0:00:37  0:00:14  128k\r 74 6725k   74 5023k    0     0   129k      0  0:00:51  0:00:38  0:00:13  125k\r 76 6725k   76 5154k    0     0   129k      0  0:00:51  0:00:39  0:00:12  125k\r 78 6725k   78 5295k    0     0   129k      0  0:00:51  0:00:40  0:00:11  127k\r 81 6725k   81 5448k    0     0   130k      0  0:00:51  0:00:41  0:00:10  132k\r 82 6725k   82 5562k    0     0   129k      0  0:00:51  0:00:42  0:00:09  127k\r 85 6725k   85 5719k    0     0   130k      0  0:00:51  0:00:43  0:00:08  135k\r 86 6725k   86 5837k    0     0   130k      0  0:00:51  0:00:44  0:00:07  134k\r 88 6725k   88 5955k    0     0   129k      0  0:00:51  0:00:45  0:00:06  130k\r 90 6725k   90 6080k    0     0   129k      0  0:00:51  0:00:46  0:00:05  125k\r 92 6725k   92 6216k    0     0   129k      0  0:00:51  0:00:47  0:00:04  130k\r 94 6725k   94 6363k    0     0   130k      0  0:00:51  0:00:48  0:00:03  127k\r 96 6725k   96 6480k    0     0   130k      0  0:00:51  0:00:49  0:00:02  133k\r 98 6725k   98 6607k    0     0   130k      0  0:00:51  0:00:50  0:00:01  134k\r100 6725k  100 6725k    0     0   129k      0  0:00:51  0:00:51 --:--:--  132k\r100 6725k  100 6725k    0     0   129k      0  0:00:51  0:00:51 --:--:--  130k\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKTt79ub6oQg",
        "colab_type": "code",
        "outputId": "66a72e2c-23e8-404a-a198-a29841cab42b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "%%bash \n",
        "\n",
        "\n",
        "find ./mm -name '*'\n",
        "\n",
        "pip list |grep tensorflow \n",
        "free -g\n",
        "# nvidia-smi\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./mm\n",
            "./mm/1\n",
            "./mm/1/saved_model.pb\n",
            "./mm/1/assets\n",
            "./mm/1/variables\n",
            "./mm/1/variables/variables.index\n",
            "./mm/1/variables/variables.data-00001-of-00002\n",
            "./mm/1/variables/variables.data-00000-of-00001\n",
            "./mm/1/variables/variables.data-00000-of-00002\n",
            "./mm/h5.h5\n",
            "./mm/ckpt.data-00000-of-00002\n",
            "./mm/checkpoint\n",
            "./mm/ckpt.data-00001-of-00002\n",
            "./mm/ckpt.index\n",
            "mesh-tensorflow          0.0.5                \n",
            "tensorflow               1.14.0               \n",
            "tensorflow-estimator     1.14.0               \n",
            "tensorflow-gpu           2.0.0b0              \n",
            "tensorflow-hub           0.5.0                \n",
            "tensorflow-metadata      0.14.0               \n",
            "tensorflow-probability   0.7.0                \n",
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:             12           1           3           0           8          11\n",
            "Swap:             0           0           0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3CZy2O3NMp3",
        "colab_type": "code",
        "outputId": "d68cace9-6fcb-4d88-c41a-93c3e0b3b0b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-beta0\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.0.0-beta0 in /usr/local/lib/python3.6/dist-packages (2.0.0b0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.2.2)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.14.0.dev2019060501)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.1.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.33.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.11.2)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.14.0a20190603)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.16.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-beta0) (1.0.8)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta0) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta0) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0.0-beta0) (41.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-beta0) (2.8.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0-beta0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOefS7vpuO_j",
        "colab_type": "code",
        "outputId": "c21cfbab-1af6-40be-9f12-f9c0a75abddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1005
        }
      },
      "source": [
        "### for ding to use \n",
        "import tensorflow as tf \n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Input, Activation, Dense, Permute, Dropout, Conv2D, Flatten, Reshape\n",
        "from tensorflow.keras.layers import add, dot, concatenate\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.utils import get_file\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "from functools import reduce\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "import pandas as pd\n",
        "import scipy.stats\n",
        "\n",
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "from scipy import stats\n",
        "import pandas as pd\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_iters = 20\n",
        "batch_size = 1024\n",
        "display_step = 10\n",
        " \n",
        "n_input = 28\n",
        "n_step = 28\n",
        "n_hidden = 128\n",
        "n_classes = 10\n",
        " \n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        " \n",
        "x_train = x_train.reshape(-1, n_step, n_input)\n",
        "\n",
        "pprint(x_train.shape)\n",
        "\n",
        "x_test = x_test.reshape(-1, n_step, n_input)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        " \n",
        "y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, n_classes)\n",
        " \n",
        "model = Sequential()\n",
        "model.add(LSTM(n_hidden,\n",
        "#                batch_input_shape=(None, n_step, n_input),\n",
        "               input_shape=x_train.shape[1:],\n",
        "               unroll=True))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(n_classes))\n",
        "model.add(Activation('softmax'))\n",
        " \n",
        "adam = Adam(lr=learning_rate)\n",
        "\n",
        "model.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary() \n",
        "\n",
        "plot_model(model,  to_file='model.png',show_shapes=True)\n",
        "# !./tfr t model.png \n",
        "\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=training_iters,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        " \n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('LSTM test score:', scores[0])\n",
        "print('LSTM test accuracy:', scores[1])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_6 (LSTM)                (None, 128)               80384     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 81,674\n",
            "Trainable params: 81,674\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 9s 151us/sample - loss: 1.4517 - acc: 0.5066 - val_loss: 0.6632 - val_acc: 0.7909\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.4410 - acc: 0.8630 - val_loss: 0.3025 - val_acc: 0.9061\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2613 - acc: 0.9212 - val_loss: 0.2101 - val_acc: 0.9375\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1940 - acc: 0.9424 - val_loss: 0.1663 - val_acc: 0.9492\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1562 - acc: 0.9546 - val_loss: 0.1406 - val_acc: 0.9566\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.1313 - acc: 0.9609 - val_loss: 0.1261 - val_acc: 0.9607\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.1118 - acc: 0.9672 - val_loss: 0.1169 - val_acc: 0.9617\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.0984 - acc: 0.9705 - val_loss: 0.1085 - val_acc: 0.9662\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.0875 - acc: 0.9737 - val_loss: 0.0961 - val_acc: 0.9700\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.0792 - acc: 0.9762 - val_loss: 0.0911 - val_acc: 0.9703\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.0742 - acc: 0.9776 - val_loss: 0.0901 - val_acc: 0.9715\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.0678 - acc: 0.9794 - val_loss: 0.0796 - val_acc: 0.9748\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.0620 - acc: 0.9811 - val_loss: 0.0765 - val_acc: 0.9763\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.0549 - acc: 0.9836 - val_loss: 0.0759 - val_acc: 0.9758\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.0511 - acc: 0.9848 - val_loss: 0.0697 - val_acc: 0.9780\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.0513 - acc: 0.9840 - val_loss: 0.0677 - val_acc: 0.9800\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.0424 - acc: 0.9873 - val_loss: 0.0676 - val_acc: 0.9801\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.0390 - acc: 0.9886 - val_loss: 0.0709 - val_acc: 0.9781\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.0387 - acc: 0.9883 - val_loss: 0.0648 - val_acc: 0.9804\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.0338 - acc: 0.9900 - val_loss: 0.0653 - val_acc: 0.9790\n",
            "LSTM test score: 0.06526803567968309\n",
            "LSTM test accuracy: 0.979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbLBkmT5tgwo",
        "colab_type": "code",
        "outputId": "7017f1f7-ed7e-4b8c-e908-932dafd0c410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "\n",
        "import tensorflow as tf \n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Input, Activation, Dense, Permute, Dropout, Conv2D, Flatten, Reshape\n",
        "from tensorflow.keras.layers import add, dot, concatenate\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.utils import get_file\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from functools import reduce\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "x_train_all =  np.random.random([20, 28,28,1])\n",
        "y_label_all =  np.random.random([20, 26,26,1])\n",
        "\n",
        "x_train, y_test, x_label, y_label = train_test_split(x_train_all, y_label_all, test_size=0.2)\n",
        "\n",
        "\n",
        "model = Sequential(\n",
        "[\n",
        "    Conv2D(4, (3,3), activation=\"relu\", input_shape=x_train.shape[1:]), \n",
        "    Dense(1)\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, x_label, \n",
        "#             validation_data=(y_test, y_label),\n",
        "    validation_split=0.2,\n",
        "        epochs=2,\n",
        "        batch_size=10,\n",
        "        verbose=1\n",
        "   \n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 26, 26, 4)         40        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 26, 26, 1)         5         \n",
            "=================================================================\n",
            "Total params: 45\n",
            "Trainable params: 45\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 12 samples, validate on 4 samples\n",
            "Epoch 1/2\n",
            "12/12 [==============================] - 0s 24ms/sample - loss: 0.7508 - val_loss: 0.7053\n",
            "Epoch 2/2\n",
            "12/12 [==============================] - 0s 1ms/sample - loss: 0.7152 - val_loss: 0.6715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5upO0o2Fu1PB",
        "colab_type": "code",
        "outputId": "c7801314-019b-46fa-bf01-e53068582e5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "\n",
        "### linear, m_0 (+) m_1 => m_big_dim\n",
        "\n",
        "import tensorflow as tf \n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from tensorflow.keras.layers import add, dot, concatenate\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.utils import get_file\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from functools import reduce\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# x0,y0,  x1,y1 = train_test_split(x,y,test_size=0.2)\n",
        "\n",
        "### main_\n",
        "id_a_np = np.random.random([1,2,2])\n",
        "id_b_np = np.random.random([1,1,2])\n",
        "\n",
        "id_a_np[0,0,0] = 1.0\n",
        "id_a_np[0,0,1] = 0.1\n",
        "id_a_np[0,1,0] = 2.0\n",
        "id_a_np[0,1,1] = 0.2\n",
        "\n",
        "\n",
        "id_b_np[0,0,0] = -3\n",
        "id_b_np[0,0,1] = -7\n",
        "\n",
        "id_a = Input(id_a_np.shape[1:])\n",
        "id_b = Input(id_b_np.shape[1:])\n",
        "\n",
        "\n",
        "\n",
        "id_ans = dot([id_a, id_b], axes=[2,2])\n",
        "\n",
        "model = Model([id_a, id_b], id_ans)\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "\n",
        "print(id_a_np)\n",
        "print()\n",
        "print(id_b_np)\n",
        "\n",
        "\n",
        "id_predict =  model.predict([id_a_np, id_b_np])\n",
        "# model.predict([np.random.random(2,3) , np.random.random(4,3)] )\n",
        "\n",
        "id_predict.shape\n",
        "\n",
        "print()\n",
        "print(id_predict)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           (None, 2, 2)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           (None, 1, 2)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 2, 1)         0           input_13[0][0]                   \n",
            "                                                                 input_14[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "[[[1.  0.1]\n",
            "  [2.  0.2]]]\n",
            "\n",
            "[[[-3. -7.]]]\n",
            "\n",
            "[[[-3.7]\n",
            "  [-7.4]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A6VuzdrWlCj",
        "colab_type": "code",
        "outputId": "73c19a31-ba3f-4c9b-9bd2-d11b669e2111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "### linear, m_0 (+) m_1 => m_big_dim\n",
        "\n",
        "import tensorflow as tf \n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from tensorflow.keras.layers import add, dot, concatenate\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.utils import get_file\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from functools import reduce\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# x0,y0,  x1,y1 = train_test_split(x,y,test_size=0.2)\n",
        "\n",
        "\n",
        "def plot_history(histories, key='binary_crossentropy'):\n",
        "    plt.figure(figsize=(8,5))\n",
        "\n",
        "    for name, history in histories:\n",
        "        val = plt.plot(history.epoch, history.history['val_'+key], '--', label=name.title()+' Val')\n",
        "        plt.plot(history.epoch, history.history[key], color=val[0].get_color(), label=name.title()+' Train')\n",
        "\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(key.replace('_',' ').title())\n",
        "    plt.legend()\n",
        "\n",
        "    plt.xlim([0,max(history.epoch)])\n",
        "\n",
        "def get_model(i_0, i_1):\n",
        "    m_0 = Sequential([\n",
        "    Dense(id_label_all.shape[-1]*2, activation='linear', input_shape= i_0.shape[1:])\n",
        "        \n",
        "#         Dense(id_label_all.shape[-1]*2,  activation='relu')\n",
        "        ])\n",
        "\n",
        "\n",
        "    m_1 = Sequential([\n",
        "        Dense(id_label_all.shape[-1]*3,  activation='linear', input_shape= i_1.shape[1:]),\n",
        "        Dense(id_label_all.shape[-1]*2, activation='linear'), \n",
        "        ])\n",
        "\n",
        "    id_ans = response = add([m_0(i_0),m_1(i_1)])  # must use add( ), if not , show error on model save\n",
        "\n",
        "    id_ans = Dense(id_label_all.shape[-1])(id_ans)\n",
        "\n",
        "\n",
        "    \n",
        "    model =  Model([i_0, i_1], id_ans)\n",
        "    \n",
        "#     plot_model(m_0,  to_file='m_0.png',show_shapes=True)\n",
        "#     !./tfr t m_0.png\n",
        "\n",
        "#     plot_model(m_1,  to_file='m_1.png',show_shapes=True)\n",
        "#     !./tfr t m_1.png\n",
        "    \n",
        "#     plot_model(model,  to_file='model.png',show_shapes=True)\n",
        "#     !./tfr t model.png\n",
        "    \n",
        "    return model\n",
        "    # x_train_0 (+) x_train_1 => x_label\n",
        "    # y_test_0  (+) y_test_1 => y_label    \n",
        "\n",
        "    \n",
        "    \n",
        "### main__    \n",
        "### \n",
        "flag_train = 1\n",
        "###\n",
        "\n",
        "x_items = 80000\n",
        "if not flag_train:\n",
        "    x_items = int(x_items/100.0)\n",
        "\n",
        "x_dim_train_0 = 6\n",
        "\n",
        "\n",
        "id_train_all_0 = np.random.random([x_items, 3,x_dim_train_0] )    \n",
        "\n",
        "id_train_all_1 = np.random.random([x_items, 3,int(x_dim_train_0/2.0)] )    \n",
        "\n",
        "id_train_all_1_ = np.concatenate((id_train_all_1, id_train_all_1*2 + 1), axis=2)\n",
        "\n",
        "id_label_all = id_train_all_0 + id_train_all_1_ \n",
        "\n",
        "id_label_all = np.concatenate((id_label_all, id_label_all), axis=2)\n",
        "\n",
        "x_train_0, y_test_0, x_train_1, y_test_1, x_label, y_label =  train_test_split(id_train_all_0, id_train_all_1, id_label_all, test_size=0.2)\n",
        "\n",
        "\n",
        "\n",
        "### jd define model \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# x_train_0 (+) x_train_1 => x_label\n",
        "# y_test_0  (+) y_test_1 => y_label\n",
        "\n",
        "if not os.path.exists(\"./mm\"):\n",
        "    !mkdir  mm\n",
        "    !ls mm\n",
        "\n",
        "model = None\n",
        "\n",
        "if flag_train:\n",
        "    i_0 = Input(id_train_all_0.shape[1:])\n",
        "    i_1 = Input(id_train_all_1.shape[1:])\n",
        "    model = get_model(i_0, i_1)\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "    \n",
        "    history = model.fit(\n",
        "        [x_train_0,x_train_1],\n",
        "        x_label,\n",
        "\n",
        "        validation_data=([y_test_0,y_test_1], y_label),\n",
        "        epochs=40,\n",
        "        batch_size=512,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    plot_history( [ ('baseline', history) ], key=\"loss\") # may be \"acc\" if gpu\n",
        "    model.save('./mm/h5.h5')\n",
        "    \n",
        "else:\n",
        "    model = tf.keras.models.load_model('./mm/h5.h5')\n",
        "\n",
        "model.summary()   \n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "batch_size = 3\n",
        "s_i = np.random.choice(range(len(y_test_0)), batch_size)\n",
        "y_predict =  model.predict([y_test_0[s_i], y_test_1[s_i]])\n",
        "\n",
        "\n",
        "cnt = 0\n",
        "print(s_i)\n",
        "\n",
        "for i in s_i:\n",
        "    print(y_label[i])\n",
        "    print(\"___\")\n",
        "    print(y_predict[cnt])\n",
        "    cnt = cnt + 1\n",
        "    print()\n",
        "    print()\n",
        "    \n",
        "## jd end define model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 64000 samples, validate on 16000 samples\n",
            "Epoch 1/40\n",
            "64000/64000 [==============================] - 1s 16us/sample - loss: 1.1446 - val_loss: 0.1798\n",
            "Epoch 2/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 0.1285 - val_loss: 0.0876\n",
            "Epoch 3/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 0.0646 - val_loss: 0.0474\n",
            "Epoch 4/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 0.0370 - val_loss: 0.0286\n",
            "Epoch 5/40\n",
            "64000/64000 [==============================] - 1s 9us/sample - loss: 0.0228 - val_loss: 0.0180\n",
            "Epoch 6/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 0.0145 - val_loss: 0.0116\n",
            "Epoch 7/40\n",
            "64000/64000 [==============================] - 1s 9us/sample - loss: 0.0095 - val_loss: 0.0077\n",
            "Epoch 8/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 0.0063 - val_loss: 0.0051\n",
            "Epoch 9/40\n",
            "64000/64000 [==============================] - 1s 9us/sample - loss: 0.0042 - val_loss: 0.0034\n",
            "Epoch 10/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 0.0027 - val_loss: 0.0022\n",
            "Epoch 11/40\n",
            "64000/64000 [==============================] - 1s 9us/sample - loss: 0.0017 - val_loss: 0.0014\n",
            "Epoch 12/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 0.0011 - val_loss: 8.4557e-04\n",
            "Epoch 13/40\n",
            "64000/64000 [==============================] - 1s 9us/sample - loss: 6.5839e-04 - val_loss: 5.0559e-04\n",
            "Epoch 14/40\n",
            "64000/64000 [==============================] - 1s 9us/sample - loss: 3.8976e-04 - val_loss: 2.9560e-04\n",
            "Epoch 15/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 2.2608e-04 - val_loss: 1.6974e-04\n",
            "Epoch 16/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 1.2912e-04 - val_loss: 9.6256e-05\n",
            "Epoch 17/40\n",
            "64000/64000 [==============================] - 1s 9us/sample - loss: 7.3021e-05 - val_loss: 5.4210e-05\n",
            "Epoch 18/40\n",
            "64000/64000 [==============================] - 1s 9us/sample - loss: 4.1111e-05 - val_loss: 3.0478e-05\n",
            "Epoch 19/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 2.3118e-05 - val_loss: 1.7117e-05\n",
            "Epoch 20/40\n",
            "64000/64000 [==============================] - 1s 9us/sample - loss: 1.2991e-05 - val_loss: 9.6101e-06\n",
            "Epoch 21/40\n",
            "64000/64000 [==============================] - 1s 9us/sample - loss: 7.2822e-06 - val_loss: 5.3699e-06\n",
            "Epoch 22/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 4.0531e-06 - val_loss: 2.9659e-06\n",
            "Epoch 23/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 2.2252e-06 - val_loss: 1.6114e-06\n",
            "Epoch 24/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 1.1977e-06 - val_loss: 8.5720e-07\n",
            "Epoch 25/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 6.2842e-07 - val_loss: 4.4178e-07\n",
            "Epoch 26/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 3.1951e-07 - val_loss: 2.2017e-07\n",
            "Epoch 27/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 1.5659e-07 - val_loss: 1.0554e-07\n",
            "Epoch 28/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 7.3706e-08 - val_loss: 4.8474e-08\n",
            "Epoch 29/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 3.3150e-08 - val_loss: 2.1199e-08\n",
            "Epoch 30/40\n",
            "64000/64000 [==============================] - 1s 9us/sample - loss: 1.4201e-08 - val_loss: 8.8139e-09\n",
            "Epoch 31/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 5.7661e-09 - val_loss: 3.4641e-09\n",
            "Epoch 32/40\n",
            "64000/64000 [==============================] - 1s 9us/sample - loss: 2.2113e-09 - val_loss: 1.2839e-09\n",
            "Epoch 33/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 7.9841e-10 - val_loss: 4.4567e-10\n",
            "Epoch 34/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 2.6979e-10 - val_loss: 1.4501e-10\n",
            "Epoch 35/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 8.5739e-11 - val_loss: 4.4502e-11\n",
            "Epoch 36/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 2.6062e-11 - val_loss: 1.3477e-11\n",
            "Epoch 37/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 7.9644e-12 - val_loss: 4.2561e-12\n",
            "Epoch 38/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 2.6398e-12 - val_loss: 1.5431e-12\n",
            "Epoch 39/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 1.0739e-12 - val_loss: 7.4032e-13\n",
            "Epoch 40/40\n",
            "64000/64000 [==============================] - 1s 8us/sample - loss: 5.5977e-13 - val_loss: 4.2191e-13\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 3, 6)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 3, 3)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 3, 24)        168         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 3, 24)        1032        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 3, 24)        0           sequential[1][0]                 \n",
            "                                                                 sequential_1[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 3, 12)        300         add[0][0]                        \n",
            "==================================================================================================\n",
            "Total params: 1,500\n",
            "Trainable params: 1,500\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "[13280  4400  2332]\n",
            "[[1.41162664 0.77112637 0.59974457 3.07393071 2.57277967 2.3741223\n",
            "  1.41162664 0.77112637 0.59974457 3.07393071 2.57277967 2.3741223 ]\n",
            " [1.52961482 1.67148325 1.78604113 3.38418466 3.19752002 3.38475809\n",
            "  1.52961482 1.67148325 1.78604113 3.38418466 3.19752002 3.38475809]\n",
            " [0.60514748 1.1974439  0.8423244  2.47105238 2.83728094 2.7570368\n",
            "  0.60514748 1.1974439  0.8423244  2.47105238 2.83728094 2.7570368 ]]\n",
            "___\n",
            "[[1.4116273  0.77112734 0.59974414 3.0739303  2.57278    2.3741224\n",
            "  1.4116265  0.7711252  0.5997449  3.0739312  2.5727792  2.3741212 ]\n",
            " [1.5296139  1.6714817  1.7860423  3.3841858  3.1975193  3.384757\n",
            "  1.5296153  1.6714842  1.7860401  3.3841844  3.1975212  3.3847597 ]\n",
            " [0.6051472  1.1974441  0.84232444 2.4710524  2.8372812  2.7570372\n",
            "  0.60514754 1.1974441  0.8423244  2.4710522  2.8372808  2.757037  ]]\n",
            "\n",
            "\n",
            "[[1.56701319 1.00500932 0.57570017 2.93670937 2.12116563 1.82541066\n",
            "  1.56701319 1.00500932 0.57570017 2.93670937 2.12116563 1.82541066]\n",
            " [0.73232762 0.96681902 1.39410793 1.31442961 1.95148642 3.19466719\n",
            "  0.73232762 0.96681902 1.39410793 1.31442961 1.95148642 3.19466719]\n",
            " [0.1340077  0.84934434 1.0769056  1.96891676 3.20459148 2.10031868\n",
            "  0.1340077  0.84934434 1.0769056  1.96891676 3.20459148 2.10031868]]\n",
            "___\n",
            "[[1.5670131  1.0050092  0.5757008  2.9367094  2.1211655  1.8254106\n",
            "  1.5670133  1.0050104  0.57570016 2.936709   2.1211658  1.8254111 ]\n",
            " [0.7323277  0.9668192  1.3941083  1.3144295  1.9514865  3.194667\n",
            "  0.73232746 0.96681905 1.3941079  1.3144294  1.9514863  3.1946669 ]\n",
            " [0.13400768 0.849344   1.0769058  1.9689167  3.204592   2.1003187\n",
            "  0.13400763 0.84934515 1.0769055  1.9689163  3.2045915  2.1003187 ]]\n",
            "\n",
            "\n",
            "[[1.30219976 0.84004615 1.29551451 3.77723231 2.51318016 2.65539952\n",
            "  1.30219976 0.84004615 1.29551451 3.77723231 2.51318016 2.65539952]\n",
            " [0.79940124 0.74700586 0.89918448 2.16697959 2.97178595 2.71787682\n",
            "  0.79940124 0.74700586 0.89918448 2.16697959 2.97178595 2.71787682]\n",
            " [0.50970333 0.16638361 1.09378617 1.41069763 2.17991777 3.00513803\n",
            "  0.50970333 0.16638361 1.09378617 1.41069763 2.17991777 3.00513803]]\n",
            "___\n",
            "[[1.3021994  0.84004515 1.2955148  3.7772331  2.5131798  2.6553988\n",
            "  1.3021996  0.8400468  1.2955136  3.7772317  2.513181   2.6554003 ]\n",
            " [0.79940146 0.7470064  0.89918435 2.1669796  2.9717863  2.7178767\n",
            "  0.7994011  0.7470056  0.89918464 2.1669798  2.9717855  2.7178767 ]\n",
            " [0.50970393 0.16638476 1.0937852  1.4106972  2.1799185  3.0051386\n",
            "  0.50970304 0.16638201 1.093787   1.4106977  2.179917   3.0051372 ]]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFACAYAAAClT+XXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKi11AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxAXdIc7Flpu",
        "colab_type": "code",
        "outputId": "25cb99fa-6a10-42e9-9813-e85551eeb155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2534
        }
      },
      "source": [
        "'''\n",
        "#Trains a memory network on the bAbI dataset.\n",
        "\n",
        "References:\n",
        "\n",
        "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
        "  [\"Towards AI-Complete Question Answering:\n",
        "  A Set of Prerequisite Toy Tasks\"](http://arxiv.org/abs/1502.05698)\n",
        "\n",
        "- Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
        "  [\"End-To-End Memory Networks\"](http://arxiv.org/abs/1503.08895)\n",
        "\n",
        "Reaches 98.6% accuracy on task 'single_supporting_fact_10k' after 120 epochs.\n",
        "Time per epoch: 3s on CPU (core i7).\n",
        "'''\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from tensorflow.keras.layers import add, dot, concatenate\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.utils import get_file\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from functools import reduce\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "\n",
        "def tokenize(sent):\n",
        "    '''Return the tokens of a sentence including punctuation.\n",
        "\n",
        "    >>> tokenize('Bob dropped the apple. Where is the apple?')\n",
        "    ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n",
        "    '''\n",
        "    return [x.strip() for x in re.split(r'(\\W+)?', sent) if x.strip()]\n",
        "\n",
        "\n",
        "def parse_stories(lines, only_supporting=False):\n",
        "    '''Parse stories provided in the bAbi tasks format\n",
        "\n",
        "    If only_supporting is true, only the sentences\n",
        "    that support the answer are kept.\n",
        "    '''\n",
        "    data = []\n",
        "    story = []\n",
        "    for line in lines:\n",
        "        line = line.decode('utf-8').strip()\n",
        "        nid, line = line.split(' ', 1)\n",
        "        nid = int(nid)\n",
        "        if nid == 1:\n",
        "            story = []\n",
        "        if '\\t' in line:\n",
        "            q, a, supporting = line.split('\\t')\n",
        "            q = tokenize(q)\n",
        "            if only_supporting:\n",
        "                # Only select the related substory\n",
        "                supporting = map(int, supporting.split())\n",
        "                substory = [story[i - 1] for i in supporting]\n",
        "            else:\n",
        "                # Provide all the substories\n",
        "                substory = [x for x in story if x]\n",
        "            data.append((substory, q, a))\n",
        "            story.append('')\n",
        "        else:\n",
        "            sent = tokenize(line)\n",
        "            story.append(sent)\n",
        "    return data\n",
        "\n",
        "\n",
        "def get_stories(f, only_supporting=False, max_length=None):\n",
        "    '''Given a file name, read the file,\n",
        "    retrieve the stories,\n",
        "    and then convert the sentences into a single story.\n",
        "\n",
        "    If max_length is supplied,\n",
        "    any stories longer than max_length tokens will be discarded.\n",
        "    '''\n",
        "    data = parse_stories(f.readlines(), only_supporting=only_supporting)\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "    data = [(flatten(story), q, answer) for story, q, answer in data\n",
        "            if not max_length or len(flatten(story)) < max_length]\n",
        "    return data\n",
        "\n",
        "\n",
        "def vectorize_stories(data):\n",
        "    inputs, queries, answers = [], [], []\n",
        "    for story, query, answer in data:\n",
        "        inputs.append([word_idx[w] for w in story])\n",
        "        queries.append([word_idx[w] for w in query])\n",
        "        answers.append(word_idx[answer])\n",
        "    return (pad_sequences(inputs, maxlen=story_maxlen),\n",
        "            pad_sequences(queries, maxlen=query_maxlen),\n",
        "            np.array(answers))\n",
        "\n",
        "try:\n",
        "    path = get_file('babi-tasks-v1-2.tar.gz',\n",
        "                    origin='https://s3.amazonaws.com/text-datasets/'\n",
        "                           'babi_tasks_1-20_v1-2.tar.gz')\n",
        "except:\n",
        "    print('Error downloading dataset, please download it manually:\\n'\n",
        "          '$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2'\n",
        "          '.tar.gz\\n'\n",
        "          '$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz')\n",
        "    raise\n",
        "\n",
        "\n",
        "challenges = {\n",
        "    # QA1 with 10,000 samples\n",
        "    'single_supporting_fact_10k': 'tasks_1-20_v1-2/en-10k/qa1_'\n",
        "                                  'single-supporting-fact_{}.txt',\n",
        "    # QA2 with 10,000 samples\n",
        "    'two_supporting_facts_10k': 'tasks_1-20_v1-2/en-10k/qa2_'\n",
        "                                'two-supporting-facts_{}.txt',\n",
        "}\n",
        "challenge_type = 'single_supporting_fact_10k'\n",
        "challenge = challenges[challenge_type]\n",
        "\n",
        "print('Extracting stories for the challenge:', challenge_type)\n",
        "with tarfile.open(path) as tar:\n",
        "    train_stories = get_stories(tar.extractfile(challenge.format('train')))\n",
        "    \n",
        "    print(len(train_stories))\n",
        "    print(train_stories[-2])\n",
        "    print(\"___\")\n",
        "    print(train_stories[-1])\n",
        "    \n",
        "    \n",
        "    test_stories = get_stories(tar.extractfile(challenge.format('test')))\n",
        "\n",
        "vocab = set()\n",
        "for story, q, answer in train_stories + test_stories:\n",
        "    vocab |= set(story + q + [answer])\n",
        "vocab = sorted(vocab)\n",
        "\n",
        "# Reserve 0 for masking via pad_sequences\n",
        "vocab_size = len(vocab) + 1\n",
        "story_maxlen = max(map(len, (x for x, _, _ in train_stories + test_stories)))\n",
        "query_maxlen = max(map(len, (x for _, x, _ in train_stories + test_stories)))\n",
        "\n",
        "print('-')\n",
        "print('Vocab size:', vocab_size, 'unique words')\n",
        "print('Story max length:', story_maxlen, 'words')\n",
        "print('Query max length:', query_maxlen, 'words')\n",
        "print('Number of training stories:', len(train_stories))\n",
        "print('Number of test stories:', len(test_stories))\n",
        "print('-')\n",
        "print('Here\\'s what a \"story\" tuple looks like (input, query, answer):')\n",
        "print(train_stories[0])\n",
        "print('-')\n",
        "print('Vectorizing the word sequences...')\n",
        "\n",
        "word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
        "inputs_train, queries_train, answers_train = vectorize_stories(train_stories)\n",
        "\n",
        "print(inputs_train[-1])\n",
        "print(queries_train[-1])\n",
        "print(answers_train[-1])\n",
        "\n",
        "\n",
        "inputs_test, queries_test, answers_test = vectorize_stories(test_stories)\n",
        "\n",
        "print('-')\n",
        "print('inputs: integer tensor of shape (samples, max_length)')\n",
        "print('inputs_train shape:', inputs_train.shape)\n",
        "print('inputs_test shape:', inputs_test.shape)\n",
        "print('-')\n",
        "print('queries: integer tensor of shape (samples, max_length)')\n",
        "print('queries_train shape:', queries_train.shape)\n",
        "print('queries_test shape:', queries_test.shape)\n",
        "print('-')\n",
        "print('answers: binary (1 or 0) tensor of shape (samples, vocab_size)')\n",
        "print('answers_train shape:', answers_train.shape)\n",
        "print('answers_test shape:', answers_test.shape)\n",
        "print('-')\n",
        "print('Compiling...')\n",
        "\n",
        "# placeholders\n",
        "input_sequence = Input((story_maxlen,))\n",
        "question = Input((query_maxlen,))\n",
        "\n",
        "# encoders\n",
        "# embed the input sequence into a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
        "                              output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, embedding_dim)\n",
        "\n",
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
        "                              output_dim=query_maxlen))\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, query_maxlen)\n",
        "\n",
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=64,\n",
        "                               input_length=query_maxlen))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "# output: (samples, query_maxlen, embedding_dim)\n",
        "\n",
        "# encode input sequence and questions (which are indices)\n",
        "# to sequences of dense vectors\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)\n",
        "\n",
        "# compute a 'match' between the first input vector sequence\n",
        "# and the question vector sequence\n",
        "# shape: `(samples, story_maxlen, query_maxlen)`\n",
        "print(input_encoded_m.shape)\n",
        "\n",
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation('softmax')(match)\n",
        "\n",
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)\n",
        "\n",
        "# concatenate the match matrix with the question vector sequence\n",
        "answer = concatenate([response, question_encoded])\n",
        "\n",
        "# the original paper uses a matrix multiplication for this reduction step.\n",
        "# we choose to use a RNN instead.\n",
        "answer = LSTM(32)(answer)  # (samples, 32)\n",
        "\n",
        "# one regularization layer -- more would probably be needed.\n",
        "answer = Dropout(0.3)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)\n",
        "\n",
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "plot_model(model,  to_file='model.png',show_shapes=True)\n",
        "assert(0==1)\n",
        "e\n",
        "\n",
        "# train\n",
        "model.fit([inputs_train, queries_train], answers_train,\n",
        "          batch_size=512,\n",
        "          epochs=120,\n",
        "          validation_data=([inputs_test, queries_test], answers_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting stories for the challenge: single_supporting_fact_10k\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
            "  return _compile(pattern, flags).split(string, maxsplit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "(['John', 'moved', 'to', 'the', 'bathroom', '.', 'Daniel', 'went', 'to', 'the', 'kitchen', '.', 'Sandra', 'travelled', 'to', 'the', 'kitchen', '.', 'Mary', 'travelled', 'to', 'the', 'hallway', '.', 'Sandra', 'went', 'back', 'to', 'the', 'bathroom', '.', 'John', 'went', 'back', 'to', 'the', 'kitchen', '.', 'Daniel', 'went', 'back', 'to', 'the', 'office', '.', 'Daniel', 'journeyed', 'to', 'the', 'bathroom', '.'], ['Where', 'is', 'John', '?'], 'kitchen')\n",
            "___\n",
            "(['John', 'moved', 'to', 'the', 'bathroom', '.', 'Daniel', 'went', 'to', 'the', 'kitchen', '.', 'Sandra', 'travelled', 'to', 'the', 'kitchen', '.', 'Mary', 'travelled', 'to', 'the', 'hallway', '.', 'Sandra', 'went', 'back', 'to', 'the', 'bathroom', '.', 'John', 'went', 'back', 'to', 'the', 'kitchen', '.', 'Daniel', 'went', 'back', 'to', 'the', 'office', '.', 'Daniel', 'journeyed', 'to', 'the', 'bathroom', '.', 'John', 'went', 'back', 'to', 'the', 'office', '.', 'Mary', 'travelled', 'to', 'the', 'bedroom', '.'], ['Where', 'is', 'John', '?'], 'office')\n",
            "-\n",
            "Vocab size: 22 unique words\n",
            "Story max length: 68 words\n",
            "Query max length: 4 words\n",
            "Number of training stories: 10000\n",
            "Number of test stories: 1000\n",
            "-\n",
            "Here's what a \"story\" tuple looks like (input, query, answer):\n",
            "(['Mary', 'moved', 'to', 'the', 'bathroom', '.', 'John', 'went', 'to', 'the', 'hallway', '.'], ['Where', 'is', 'Mary', '?'], 'bathroom')\n",
            "-\n",
            "Vectorizing the word sequences...\n",
            "[ 0  0  0  0  4 16 19 18  9  1  3 21 19 18 15  1  6 20 19 18 15  1  5 20\n",
            " 19 18 12  1  6 21  8 19 18  9  1  4 21  8 19 18 15  1  3 21  8 19 18 17\n",
            "  1  3 14 19 18  9  1  4 21  8 19 18 17  1  5 20 19 18 10  1]\n",
            "[ 7 13  4  2]\n",
            "17\n",
            "-\n",
            "inputs: integer tensor of shape (samples, max_length)\n",
            "inputs_train shape: (10000, 68)\n",
            "inputs_test shape: (1000, 68)\n",
            "-\n",
            "queries: integer tensor of shape (samples, max_length)\n",
            "queries_train shape: (10000, 4)\n",
            "queries_test shape: (1000, 4)\n",
            "-\n",
            "answers: binary (1 or 0) tensor of shape (samples, vocab_size)\n",
            "answers_train shape: (10000,)\n",
            "answers_test shape: (1000,)\n",
            "-\n",
            "Compiling...\n",
            "(?, 68, 64)\n",
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_15 (InputLayer)           [(None, 68)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_16 (InputLayer)           [(None, 4)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_21 (Sequential)      multiple             1408        input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "sequential_23 (Sequential)      (None, 4, 64)        1408        input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dot_7 (Dot)                     (None, 68, 4)        0           sequential_21[1][0]              \n",
            "                                                                 sequential_23[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 68, 4)        0           dot_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sequential_22 (Sequential)      multiple             88          input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 68, 4)        0           activation_14[0][0]              \n",
            "                                                                 sequential_22[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "permute_7 (Permute)             (None, 4, 68)        0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 4, 132)       0           permute_7[0][0]                  \n",
            "                                                                 sequential_23[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   (None, 32)           21120       concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_31 (Dropout)            (None, 32)           0           lstm_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 22)           726         dropout_31[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 22)           0           dense_7[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 24,750\n",
            "Trainable params: 24,750\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-68782b931c51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCOtcYhvafYu",
        "colab_type": "code",
        "outputId": "94794e66-1a4e-4a7f-f293-51b50b284348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "!pip install tf-nightly\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# set parameters:\n",
        "max_features = 177\n",
        "maxlen = 222\n",
        "batch_size = 32\n",
        "embedding_dims = 33\n",
        "filters = 77\n",
        "kernel_size = 3\n",
        "hidden_dims = 250\n",
        "epochs = 2\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "\n",
        "\n",
        "word_to_id = imdb.get_word_index()\n",
        "\n",
        "# print(word_to_id)\n",
        "\n",
        "word_to_id = {k:(v+3) for k,v in word_to_id.items()}\n",
        "word_to_id[\"<PAD>\"] = 0\n",
        "word_to_id[\"<START>\"] = 1\n",
        "word_to_id[\"<UNK>\"] = 2\n",
        "\n",
        "id_to_word = {value:key for key,value in word_to_id.items()}\n",
        "print(' '.join(id_to_word[id] for id in x_train[0] ))\n",
        "\n",
        "\n",
        "\n",
        "assert(0==1)\n",
        "\n",
        "\n",
        "\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_train[0:3])\n",
        "\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "print(x_train.shape)\n",
        "\n",
        "\n",
        "print(x_train[0:3])\n",
        "\n",
        "\n",
        "print()\n",
        "print(y_train[0:3])\n",
        "\n",
        "print(x_test.shape)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print(x_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "\n",
        "# we start off with an efficient embedding layer which maps\n",
        "# our vocab indices into embedding_dims dimensions\n",
        "model.add(Embedding(max_features,\n",
        "                    embedding_dims,\n",
        "                    input_length=maxlen))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# we add a Convolution1D, which will learn filters\n",
        "# word group filters of size filter_length:\n",
        "model.add(Conv1D(filters,\n",
        "                 kernel_size,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "# we use max pooling:\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "# We add a vanilla hidden layer:\n",
        "model.add(Dense(hidden_dims))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary() \n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/06/c1ee8952e0b54eacc19239850ec90ae2a909a4800c4c3db7470be9ce5ecc/tf_nightly-1.15.0.dev20190725-cp36-cp36m-manylinux1_x86_64.whl (102.1MB)\n",
            "\u001b[K     || 102.1MB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.1.7)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Collecting tb-nightly<1.16.0a0,>=1.15.0a0 (from tf-nightly)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/7c/cdcf7d464f840ab727c5dd6d23d0874db3a2f6c8ee28a63649134c4cc9af/tb_nightly-1.15.0a20190724-py3-none-any.whl (4.1MB)\n",
            "\u001b[K     || 4.1MB 18.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.33.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.8.0)\n",
            "Collecting opt-einsum>=2.3.2 (from tf-nightly)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/d6/44792ec668bcda7d91913c75237314e688f70415ab2acd7172c845f0b24f/opt_einsum-2.3.2.tar.gz (59kB)\n",
            "\u001b[K     || 61kB 19.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.7.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.16.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.11.2)\n",
            "Collecting tf-estimator-nightly (from tf-nightly)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/bc/8466194619943d6a1bcba5adc9ac22eb132cd88c2d96e3b3243664d35f5e/tf_estimator_nightly-1.14.0.dev2019072501-py2.py3-none-any.whl (501kB)\n",
            "\u001b[K     || 501kB 38.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tf-nightly) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.16.0a0,>=1.15.0a0->tf-nightly) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.16.0a0,>=1.15.0a0->tf-nightly) (0.15.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tf-nightly) (2.8.0)\n",
            "Building wheels for collected packages: opt-einsum\n",
            "  Building wheel for opt-einsum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/3e/a3/b351fae0cbf15373c2136a54a70f43fea5fe91d8168a5faaa4\n",
            "Successfully built opt-einsum\n",
            "Installing collected packages: tb-nightly, opt-einsum, tf-estimator-nightly, tf-nightly\n",
            "Successfully installed opt-einsum-2.3.2 tb-nightly-1.15.0a20190724 tf-estimator-nightly-1.14.0.dev2019072501 tf-nightly-1.15.0.dev20190725\n",
            "Loading data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "<START> this film was just <UNK> <UNK> <UNK> <UNK> story <UNK> <UNK> really <UNK> the part they <UNK> and you could just <UNK> being there <UNK> <UNK> is an <UNK> <UNK> and now the same being director <UNK> <UNK> <UNK> from the same <UNK> <UNK> as <UNK> so i <UNK> the <UNK> there was a real <UNK> with this film the <UNK> <UNK> <UNK> the film were great it was just <UNK> so much that i <UNK> the film as <UNK> as it was <UNK> for <UNK> and would <UNK> it to <UNK> to watch and the <UNK> <UNK> was <UNK> really <UNK> at the end it was so <UNK> and you know what they say if you <UNK> at a film it <UNK> have been good and this <UNK> was also <UNK> to the two little <UNK> that <UNK> the <UNK> of <UNK> and <UNK> they were just <UNK> <UNK> are <UNK> <UNK> out of the <UNK> <UNK> i think because the <UNK> that <UNK> them all <UNK> up are such a <UNK> <UNK> for the <UNK> film but these <UNK> are <UNK> and should be <UNK> for what they have <UNK> don't you think the <UNK> story was so <UNK> because it was <UNK> and was <UNK> life after all that was <UNK> with <UNK> all\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0725 09:16:58.844969 140455618811776 module_wrapper.py:136] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/module_wrapper.py:163: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7aa424841efe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxHa9QSMh-U7",
        "colab_type": "code",
        "outputId": "52a28488-47b1-4638-c3fd-43be1d5468a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1311
        }
      },
      "source": [
        "'''Trains a denoising autoencoder on MNIST dataset.\n",
        "Denoising is one of the classic applications of autoencoders.\n",
        "The denoising process removes unwanted noise that corrupted the\n",
        "true signal.\n",
        "Noise + Data ---> Denoising Autoencoder ---> Data\n",
        "Given a training dataset of corrupted data as input and\n",
        "true signal as output, a denoising autoencoder can recover the\n",
        "hidden structure to generate clean data.\n",
        "This example has modular design. The encoder, decoder and autoencoder\n",
        "are 3 models that share weights. For example, after training the\n",
        "autoencoder, the encoder can be used to  generate latent vectors\n",
        "of input data for low-dim visualization like PCA or TSNE.\n",
        "'''\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from tensorflow import keras as keras\n",
        "# import keras\n",
        "from tensorflow.keras.layers import Activation, Dense, Input\n",
        "from tensorflow.keras.layers import Conv2D, Flatten\n",
        "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "np.random.seed(1337)\n",
        "\n",
        "# MNIST dataset\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "image_size = x_train.shape[1]\n",
        "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
        "x_test = np.reshape(x_test, [-1, image_size, image_size, 1])\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# Generate corrupted MNIST images by adding noise with normal dist\n",
        "# centered at 0.5 and std=0.5\n",
        "noise = np.random.normal(loc=0.5, scale=0.5, size=x_train.shape)\n",
        "x_train_noisy = x_train + noise\n",
        "noise = np.random.normal(loc=0.5, scale=0.5, size=x_test.shape)\n",
        "x_test_noisy = x_test + noise\n",
        "\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
        "\n",
        "# Network parameters\n",
        "input_shape = (image_size, image_size, 1)\n",
        "batch_size = 128\n",
        "kernel_size = 3\n",
        "latent_dim = 16\n",
        "# Encoder/Decoder number of CNN layers and filters per layer\n",
        "layer_filters = [32, 64]\n",
        "\n",
        "# Build the Autoencoder Model\n",
        "# First build the Encoder Model\n",
        "inputs = Input(shape=input_shape, name='encoder_input')\n",
        "x = inputs\n",
        "# Stack of Conv2D blocks\n",
        "# Notes:\n",
        "# 1) Use Batch Normalization before ReLU on deep networks\n",
        "# 2) Use MaxPooling2D as alternative to strides>1\n",
        "# - faster but not as good as strides>1\n",
        "for filters in layer_filters:\n",
        "    shape = K.int_shape(x)\n",
        "    print(shape)\n",
        "    x = Conv2D(filters=filters,\n",
        "               kernel_size=kernel_size,\n",
        "               strides=2,\n",
        "               activation='relu',\n",
        "               padding='same')(x)\n",
        "\n",
        "# Shape info needed to build Decoder Model\n",
        "shape = K.int_shape(x)\n",
        "\n",
        "\n",
        "print(shape)\n",
        "\n",
        "\n",
        "\n",
        "# Generate the latent vector\n",
        "x = Flatten()(x)\n",
        "latent = Dense(latent_dim, name='latent_vector')(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate Encoder Model\n",
        "encoder = Model(inputs, latent, name='encoder')\n",
        "encoder.summary()\n",
        "\n",
        "\n",
        "\n",
        "# Build the Decoder Model\n",
        "latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
        "\n",
        "print(K.int_shape(latent_inputs))\n",
        "\n",
        "x = Dense(shape[1] * shape[2] * shape[3])(latent_inputs)\n",
        "print(K.int_shape(x))\n",
        "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
        "print(K.int_shape(x))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Stack of Transposed Conv2D blocks\n",
        "# Notes:\n",
        "# 1) Use Batch Normalization before ReLU on deep networks\n",
        "# 2) Use UpSampling2D as alternative to strides>1\n",
        "# - faster but not as good as strides>1\n",
        "for filters in layer_filters[::-1]:\n",
        "    shape = K.int_shape(x)\n",
        "    print(shape)\n",
        "    x = Conv2DTranspose(filters=filters,\n",
        "                        kernel_size=kernel_size,\n",
        "                        strides=2,\n",
        "                        activation='relu',\n",
        "                        padding='same')(x)\n",
        "\n",
        "shape = K.int_shape(x)\n",
        "print(shape)   \n",
        "\n",
        "\n",
        "x = Conv2DTranspose(filters=1,\n",
        "                    kernel_size=kernel_size,\n",
        "                    padding='same')(x)\n",
        "print(K.int_shape(x))\n",
        "\n",
        "outputs = Activation('sigmoid', name='decoder_output')(x)\n",
        "print(K.int_shape(outputs))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate Decoder Model\n",
        "decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "decoder.summary()\n",
        "\n",
        "\n",
        "\n",
        "# Autoencoder = Encoder + Decoder\n",
        "# Instantiate Autoencoder Model\n",
        "autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\n",
        "autoencoder.summary()\n",
        "\n",
        "autoencoder.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(x_train_noisy,\n",
        "                x_train,\n",
        "                validation_data=(x_test_noisy, x_test),\n",
        "                epochs=30,\n",
        "                batch_size=batch_size)\n",
        "\n",
        "# Predict the Autoencoder output from corrupted test images\n",
        "x_decoded = autoencoder.predict(x_test_noisy)\n",
        "\n",
        "# Display the 1st 8 corrupted and denoised images\n",
        "rows, cols = 10, 30\n",
        "num = rows * cols\n",
        "imgs = np.concatenate([x_test[:num], x_test_noisy[:num], x_decoded[:num]])\n",
        "imgs = imgs.reshape((rows * 3, cols, image_size, image_size))\n",
        "imgs = np.vstack(np.split(imgs, rows, axis=1))\n",
        "imgs = imgs.reshape((rows * 3, -1, image_size, image_size))\n",
        "imgs = np.vstack([np.hstack(i) for i in imgs])\n",
        "imgs = (imgs * 255).astype(np.uint8)\n",
        "plt.figure()\n",
        "plt.axis('off')\n",
        "plt.title('Original images: top rows, '\n",
        "          'Corrupted Input: middle rows, '\n",
        "          'Denoised Input:  third rows')\n",
        "plt.imshow(imgs, interpolation='none', cmap='gray')\n",
        "Image.fromarray(imgs).save('corrupted_and_denoised.png')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 28, 28, 1)\n",
            "(None, 14, 14, 32)\n",
            "(None, 7, 7, 64)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 14, 14, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "latent_vector (Dense)        (None, 16)                50192     \n",
            "=================================================================\n",
            "Total params: 69,008\n",
            "Trainable params: 69,008\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(None, 16)\n",
            "(None, 3136)\n",
            "(None, 7, 7, 64)\n",
            "(None, 7, 7, 64)\n",
            "(None, 14, 14, 64)\n",
            "(None, 28, 28, 32)\n",
            "(None, 28, 28, 1)\n",
            "(None, 28, 28, 1)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3136)              53312     \n",
            "_________________________________________________________________\n",
            "reshape_5 (Reshape)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_10 (Conv2DT (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_11 (Conv2DT (None, 28, 28, 32)        18464     \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_12 (Conv2DT (None, 28, 28, 1)         289       \n",
            "_________________________________________________________________\n",
            "decoder_output (Activation)  (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 108,993\n",
            "Trainable params: 108,993\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              (None, 16)                69008     \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 28, 28, 1)         108993    \n",
            "=================================================================\n",
            "Total params: 178,001\n",
            "Trainable params: 178,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b79a25a84719>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0mautoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'autoencoder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzpnJmmYER6z",
        "colab_type": "code",
        "outputId": "b77b6ab2-87e0-44ab-c1c1-a1d6aa5c7407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1493
        }
      },
      "source": [
        "# conv on mnist data \n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.preprocessing as prep \n",
        "from IPython.display import display\n",
        "\n",
        "### sub list ###\n",
        "\n",
        "def gen_train_label(rows, img_rows, img_cols, y_dim):\n",
        "    (x_train, x_label), (y_test, y_label) = keras.datasets.mnist.load_data()  # 6000 28 28\n",
        "    x_train = x_train.reshape(-1, img_rows, img_cols, 1)\n",
        "    y_test = y_test.reshape(-1, img_rows, img_cols, 1)\n",
        "    x_train = x_train.astype('float32')\n",
        "    y_test = y_test.astype('float32')\n",
        "    \n",
        "    x_train /= 255.0\n",
        "    y_test /= 255.0\n",
        "        \n",
        "    x_label = keras.utils.to_categorical(x_label, y_dim)\n",
        "    y_label = keras.utils.to_categorical(y_label, y_dim)\n",
        "    \n",
        "#     x_train = np.random.random([rows,x_dim])\n",
        "#     x_label = np.random.random([rows,y_dim])\n",
        "#     x_label.fill(0.0)\n",
        "\n",
        "#     for idx in range(rows):\n",
        "#         e_ = x_train[idx]\n",
        "\n",
        "#         e_c = ( (e_[0] * 1 + e_[-1] * 2) - 0.66 ) * 1.0\n",
        "#         e_c = e_[0] + e_[-1]\n",
        "#         x_label[idx][0] = np.argmax(e_)\n",
        "#         x_label[idx][-1] = np.argmin(e_)\n",
        "\n",
        "    return [x_train, x_label, y_test, y_label]\n",
        "\n",
        "def norm_x_y_data(X_train, X_test):\n",
        "    #import sklearn.preprocessing as prep \n",
        "    preprocessor = prep.StandardScaler().fit(X_train)\n",
        "    X_train = preprocessor.transform(X_train)\n",
        "    X_test = preprocessor.transform(X_test)\n",
        "    # X_train_R0=preprocessor.inverse_transform(X_test)    \n",
        "    return [X_train, X_test, preprocessor]\n",
        "\n",
        "def plot_history(histories, key='binary_crossentropy'):\n",
        "    plt.figure(figsize=(8,5))\n",
        "\n",
        "    for name, history in histories:\n",
        "        val = plt.plot(history.epoch, history.history['val_'+key], '--', label=name.title()+' Val')\n",
        "        plt.plot(history.epoch, history.history[key], color=val[0].get_color(), label=name.title()+' Train')\n",
        "\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(key.replace('_',' ').title())\n",
        "    plt.legend()\n",
        "\n",
        "    plt.xlim([0,max(history.epoch)])\n",
        "\n",
        "\n",
        "\n",
        "def show_predict(y_test, y_label, y_predict):\n",
        "    cnt_err = 0\n",
        "    for i in range(len(y_test)):\n",
        "        if np.argmax(y_label[i]) != np.argmax(y_predict[i]):\n",
        "            print (y_test[i])\n",
        "            print (y_label[i] , \" vs \" , y_predict[i])\n",
        "            e_ =  y_test[i]\n",
        "            print (\"- diff is :\" , np.abs(np.sqrt(e_[0] * e_[0] + e_[-1] * e_[-1]) - 0.66 ))\n",
        "            cnt_err += 1\n",
        "            print()\n",
        "    print(\"- cnt error is \", cnt_err)\n",
        "    print()\n",
        "\n",
        "def get_mm_filesize(param_num):\n",
        "    R0 = 33.9765625\n",
        "    each_size = 0.01171875\n",
        "    return R0 + param_num * each_size \n",
        "\n",
        "def gen_model(img_rows, img_cols, y_dim):\n",
        "    \n",
        "    \n",
        "#     baseline_model.compile(optimizer='adam',\n",
        "#                        loss='binary_crossentropy',\n",
        "#                        metrics=['accuracy', 'binary_crossentropy'])    \n",
        "    input_shape= (img_rows, img_cols, 1)\n",
        "    baseline_model = keras.Sequential([\n",
        "        # `input_shape` is only required here so that `.summary` works.\n",
        "        #         keras.layers.Dense(8, activation=tf.nn.relu, input_shape=(x_dim,)),\n",
        "        #     keras.layers.Dense(128, input_shape=(x_dim,)),\n",
        "        keras.layers.Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=input_shape), \n",
        "\n",
        "        keras.layers.Conv2D(16, kernel_size=(3, 3),  activation='relu'), \n",
        "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        keras.layers.Dropout(0.22),\n",
        "        keras.layers.Flatten(),\n",
        "\n",
        "        keras.layers.Dense(16, activation='relu'),\n",
        "\n",
        "        keras.layers.Dropout(0.22),\n",
        "        keras.layers.Dense(y_dim, activation='softmax')\n",
        "\n",
        "    ])\n",
        "    \n",
        "    \n",
        "    \n",
        "#     baseline_model.summary()\n",
        "    \n",
        "    baseline_model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                  optimizer=keras.optimizers.Adam(),\n",
        "                  metrics=['accuracy'])\n",
        "#     opt = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "    \n",
        "#     baseline_model.compile(\n",
        "#         optimizer=tf.keras.optimizers.Adam(),\n",
        "\n",
        "#                 loss=tf.keras.losses.binary_crossentropy,\n",
        "#                 metrics=['accuracy','binary_crossentropy'])\n",
        "   \n",
        "    return baseline_model    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "#     !perl -e \"print time\"\n",
        "    preprocessor = None\n",
        "    import os\n",
        "    if not os.path.exists(\"./mm\"):\n",
        "        !mkdir  mm\n",
        "        !ls mm\n",
        "    \n",
        "    \n",
        "    rows = 60000\n",
        "    img_rows = 28\n",
        "    img_cols = 28\n",
        "    y_dim = 10\n",
        "   \n",
        "    flag_train = 1\n",
        "    \n",
        "    \n",
        "\n",
        "    key_acc = \"acc\"\n",
        "    \n",
        "    if \"WINDIR\" in os.environ :\n",
        "        key_acc = \"accuracy\"  # my windows   \n",
        "        \n",
        "    if \"HOME\" in os.environ and os.environ[\"HOME\"] == \"/home/bgi902\":\n",
        "        key_acc = \"accuracy\"\n",
        "    \n",
        "        \n",
        "\n",
        "    [x_train, x_label, y_test, y_label] = gen_train_label(rows, img_rows, img_cols, y_dim)\n",
        "   \n",
        "    \n",
        "    \n",
        "#     [x_train, y_test, preprocessor] = norm_x_y_data(x_train, y_test)\n",
        "    \n",
        "    \n",
        "    if flag_train:\n",
        "        baseline_model = gen_model(img_rows, img_cols, y_dim)\n",
        "        baseline_model.summary()\n",
        "\n",
        "\n",
        "    #     early_stop = keras.callbacks.EarlyStopping(monitor=\"val_\" + key_acc,  patience=7)\n",
        "        !perl -e \"print time\"\n",
        "        print()\n",
        "        \n",
        "        baseline_history = baseline_model.fit(x_train, x_label,\n",
        "              batch_size=512,\n",
        "              epochs=10,\n",
        "              verbose=0,\n",
        "              validation_data=(y_test, y_label)\n",
        "             )\n",
        "        \n",
        "#         baseline_history = baseline_model.fit(x_train,\n",
        "#                                           x_label,\n",
        "#                                           epochs=40,\n",
        "#                                           batch_size=200,\n",
        "#                                           validation_data=(y_test, y_label),\n",
        "#     #                                       callbacks=[early_stop],\n",
        "#                                           verbose=0)    \n",
        "\n",
        "        !perl -e \"print time\"\n",
        "        print()\n",
        "\n",
        "\n",
        "        plot_history( [ ('baseline', baseline_history) ], key=\"loss\") # may be \"acc\" if gpu\n",
        "    #     plot_history( [ ('baseline', baseline_history) ], key=\"binary_crossentropy\")\n",
        "\n",
        "        print(baseline_history.history.keys(), \"\\n\")\n",
        "\n",
        "        # history to DF\n",
        "        baseline_history_ = pd.DataFrame(baseline_history.history)\n",
        "        baseline_history_['epoch'] = baseline_history.epoch\n",
        "        print(baseline_history_.shape)\n",
        "        print()\n",
        "        display(baseline_history_.tail())\n",
        "\n",
        "\n",
        "\n",
        "    #     show_predict(y_test[s_i], y_label[s_i], y_predict)\n",
        "\n",
        "        print (baseline_model.evaluate(y_test, y_label))\n",
        "\n",
        "\n",
        "    if 1:\n",
        "        if flag_train:\n",
        "            baseline_model.save('./mm/h5.h5')\n",
        "            \n",
        "        baseline_model_new_h5 = tf.keras.models.load_model('./mm/h5.h5')\n",
        "        #     baseline_model_new_h5.summary()\n",
        "        print (baseline_model_new_h5.evaluate(y_test, y_label))\n",
        "        \n",
        "        \n",
        "#         print ( baseline_model_new_h5.predict(preprocessor.transform(np.random.random([11,x_dim]))) )\n",
        "        batch_size = 10\n",
        "        s_i = np.random.choice(range(len(y_test)), batch_size)\n",
        "\n",
        "        y_predict = baseline_model_new_h5.predict(y_test[s_i])\n",
        "        print(\"______________________\")\n",
        "        \n",
        "        \n",
        "        print(y_test[s_i][0].shape)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "#         display(y_test[s_i])\n",
        "        display(y_label[s_i])\n",
        "        for i in range(10):\n",
        "            print(i , \" => \"  , np.argmax(y_predict[i]) , \" vs \", np.argmax(y_label[s_i][i]))\n",
        "        \n",
        "\n",
        "\n",
        "    if 0:\n",
        "        baseline_model.save_weights('./mm/ckpt')\n",
        "        baseline_model_new_ckp = gen_model(img_rows, img_cols, y_dim)\n",
        "        #     baseline_model_new_ckp.summary()\n",
        "        baseline_model_new_ckp.load_weights('./mm/ckpt')\n",
        "        print (baseline_model_new_ckp.evaluate(y_test, y_label))\n",
        "        baseline_model_new_ckp.summary()\n",
        "\n",
        "    print (\"- h5 networks filesize is : \" , get_mm_filesize(baseline_model.count_params()) , \" kbytes\")\n",
        "\n",
        "### lib_ end \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                36880     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 39,530\n",
            "Trainable params: 39,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1557213458\n",
            "1557213484\n",
            "dict_keys(['loss', 'acc', 'val_loss', 'val_acc']) \n",
            "\n",
            "(10, 5)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_acc</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.211328</td>\n",
              "      <td>0.934383</td>\n",
              "      <td>0.071399</td>\n",
              "      <td>0.9774</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.200187</td>\n",
              "      <td>0.937400</td>\n",
              "      <td>0.068690</td>\n",
              "      <td>0.9794</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.187592</td>\n",
              "      <td>0.942850</td>\n",
              "      <td>0.064627</td>\n",
              "      <td>0.9806</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.179984</td>\n",
              "      <td>0.944167</td>\n",
              "      <td>0.059541</td>\n",
              "      <td>0.9818</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.169886</td>\n",
              "      <td>0.948567</td>\n",
              "      <td>0.057975</td>\n",
              "      <td>0.9827</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss       acc  val_loss  val_acc  epoch\n",
              "5  0.211328  0.934383  0.071399   0.9774      5\n",
              "6  0.200187  0.937400  0.068690   0.9794      6\n",
              "7  0.187592  0.942850  0.064627   0.9806      7\n",
              "8  0.179984  0.944167  0.059541   0.9818      8\n",
              "9  0.169886  0.948567  0.057975   0.9827      9"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 77us/sample - loss: 0.0580 - acc: 0.9827\n",
            "[0.05797498732553795, 0.9827]\n",
            "10000/10000 [==============================] - 1s 91us/sample - loss: 0.0580 - acc: 0.9827\n",
            "[0.05797498732553795, 0.9827]\n",
            "______________________\n",
            "(28, 28, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0  =>  8  vs  9\n",
            "1  =>  1  vs  1\n",
            "2  =>  8  vs  8\n",
            "3  =>  8  vs  8\n",
            "4  =>  9  vs  9\n",
            "5  =>  3  vs  3\n",
            "6  =>  1  vs  1\n",
            "7  =>  4  vs  4\n",
            "8  =>  2  vs  2\n",
            "9  =>  4  vs  4\n",
            "- h5 networks filesize is :  497.21875  kbytes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFACAYAAAClT+XXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIikif8H8SDHsB4SgjkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAJxHZBA1qVu",
        "colab_type": "code",
        "outputId": "ff2fe2a8-741a-4cad-cd47-4dc2e1d27d44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# predict the idx of max , min \n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.preprocessing as prep \n",
        "from IPython.display import display\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "### sub list ###\n",
        "\n",
        "def gen_train_label(rows, x_dim, y_dim):\n",
        "    x_train = np.random.random([rows,x_dim])\n",
        "    x_label = np.random.random([rows,y_dim])\n",
        "    x_label.fill(0.0)\n",
        "\n",
        "    for idx in range(rows):\n",
        "        e_ = x_train[idx]\n",
        "\n",
        "#         e_c = ( (e_[0] * 1 + e_[-1] * 2) - 0.66 ) * 1.0\n",
        "#         e_c = e_[0] + e_[-1]\n",
        "        x_label[idx][0] = np.argmax(e_)\n",
        "        x_label[idx][-1] = np.argmin(e_)\n",
        "\n",
        "    return [x_train, x_label]\n",
        "\n",
        "def norm_x_y_data(X_train, X_test):\n",
        "    #import sklearn.preprocessing as prep \n",
        "    preprocessor = prep.StandardScaler().fit(X_train)\n",
        "    X_train = preprocessor.transform(X_train)\n",
        "    X_test = preprocessor.transform(X_test)\n",
        "    # X_train_R0=preprocessor.inverse_transform(X_test)    \n",
        "    return [X_train, X_test, preprocessor]\n",
        "\n",
        "def plot_history(histories, key='binary_crossentropy'):\n",
        "    plt.figure(figsize=(8,5))\n",
        "\n",
        "    for name, history in histories:\n",
        "        val = plt.plot(history.epoch, history.history['val_'+key], '--', label=name.title()+' Val')\n",
        "        plt.plot(history.epoch, history.history[key], color=val[0].get_color(), label=name.title()+' Train')\n",
        "\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(key.replace('_',' ').title())\n",
        "    plt.legend()\n",
        "\n",
        "    plt.xlim([0,max(history.epoch)])\n",
        "\n",
        "\n",
        "\n",
        "def show_predict(y_test, y_label, y_predict):\n",
        "    cnt_err = 0\n",
        "    for i in range(len(y_test)):\n",
        "        if np.argmax(y_label[i]) != np.argmax(y_predict[i]):\n",
        "            print (y_test[i])\n",
        "            print (y_label[i] , \" vs \" , y_predict[i])\n",
        "            e_ =  y_test[i]\n",
        "            print (\"- diff is :\" , np.abs(np.sqrt(e_[0] * e_[0] + e_[-1] * e_[-1]) - 0.66 ))\n",
        "            cnt_err += 1\n",
        "            print()\n",
        "    print(\"- cnt error is \", cnt_err)\n",
        "    print()\n",
        "\n",
        "def get_mm_filesize(param_num):\n",
        "    R0 = 33.9765625\n",
        "    each_size = 0.01171875\n",
        "    return R0 + param_num * each_size \n",
        "\n",
        "def gen_model(x_dim, y_dim):\n",
        "#     baseline_model.compile(optimizer='adam',\n",
        "#                        loss='binary_crossentropy',\n",
        "#                        metrics=['accuracy', 'binary_crossentropy'])    \n",
        "\n",
        "\n",
        "    baseline_model = keras.Sequential([\n",
        "    # `input_shape` is only required here so that `.summary` works.\n",
        "#         keras.layers.Dense(8, activation=tf.nn.relu, input_shape=(x_dim,)),\n",
        "        keras.layers.Dense(128, input_shape=(x_dim,)),\n",
        "         keras.layers.Dense(128, activation=\"linear\"),\n",
        "     \n",
        "        \n",
        "        keras.layers.Dense(64, activation=\"relu\"),\n",
        "#         keras.layers.Dropout(0.3),\n",
        "#         keras.layers.Dense(y_dim, activation=tf.nn.sigmoid)\n",
        "         keras.layers.Dense(y_dim, activation=\"relu\")\n",
        "\n",
        "    ])\n",
        "    \n",
        "    \n",
        "    baseline_model.summary()\n",
        "#     opt = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "    \n",
        "#     baseline_model.compile(\n",
        "#         optimizer=tf.keras.optimizers.Adam(),\n",
        "\n",
        "#                 loss=tf.keras.losses.binary_crossentropy,\n",
        "#                 metrics=['accuracy','binary_crossentropy'])\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.RMSprop(0.001/2)\n",
        "#     optimizer=tf.keras.optimizers.Adam(0.002)\n",
        "\n",
        "    baseline_model.compile(loss='mean_squared_error',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mean_absolute_error', 'binary_crossentropy'])    \n",
        "    \n",
        "    return baseline_model    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "#     !perl -e \"print time\"\n",
        "    preprocessor = None\n",
        "    import os\n",
        "    if not os.path.exists(\"./mm\"):\n",
        "        !mkdir  mm\n",
        "        !ls mm\n",
        "    \n",
        "    \n",
        "    rows = 10000\n",
        "    x_dim = 3\n",
        "    y_dim = 2    \n",
        "    flag_train = 1\n",
        "    \n",
        "    \n",
        "\n",
        "    key_acc = \"acc\"\n",
        "    \n",
        "    if \"WINDIR\" in os.environ :\n",
        "        key_acc = \"accuracy\"  # my windows   \n",
        "        \n",
        "    if \"HOME\" in os.environ and os.environ[\"HOME\"] == \"/home/bgi902\":\n",
        "        key_acc = \"accuracy\"\n",
        "    \n",
        "        \n",
        "\n",
        "    [x_train, x_label] = gen_train_label(rows, x_dim, y_dim)\n",
        "    [y_test, y_label] = gen_train_label( int(rows/2), x_dim, y_dim)\n",
        "    \n",
        "    \n",
        "#     [x_train, y_test, preprocessor] = norm_x_y_data(x_train, y_test)\n",
        "    \n",
        "    \n",
        "    if flag_train:\n",
        "        baseline_model = gen_model(x_dim, y_dim)\n",
        "        baseline_model.summary()\n",
        "\n",
        "\n",
        "    #     early_stop = keras.callbacks.EarlyStopping(monitor=\"val_\" + key_acc,  patience=7)\n",
        "        !perl -e \"print time\"\n",
        "        print()\n",
        "        baseline_history = baseline_model.fit(x_train,\n",
        "                                          x_label,\n",
        "                                          epochs=4,\n",
        "                                          batch_size=200,\n",
        "                                          validation_data=(y_test, y_label),\n",
        "    #                                       callbacks=[early_stop],\n",
        "                                          verbose=0)    \n",
        "\n",
        "        !perl -e \"print time\"\n",
        "        print()\n",
        "\n",
        "\n",
        "        plot_history( [ ('baseline', baseline_history) ], key=\"loss\") # may be \"acc\" if gpu\n",
        "    #     plot_history( [ ('baseline', baseline_history) ], key=\"binary_crossentropy\")\n",
        "\n",
        "        print(baseline_history.history.keys(), \"\\n\")\n",
        "\n",
        "        # history to DF\n",
        "        baseline_history_ = pd.DataFrame(baseline_history.history)\n",
        "        baseline_history_['epoch'] = baseline_history.epoch\n",
        "        print(baseline_history_.shape)\n",
        "        print()\n",
        "        display(baseline_history_.tail())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #     show_predict(y_test[s_i], y_label[s_i], y_predict)\n",
        "\n",
        "        print (baseline_model.evaluate(y_test, y_label))\n",
        "\n",
        "\n",
        "    if 1:\n",
        "        if flag_train:\n",
        "            baseline_model.save('./mm/h5.h5')\n",
        "\n",
        "\n",
        "\n",
        "            \n",
        "        baseline_model_new_h5 = tf.keras.models.load_model('./mm/h5.h5')\n",
        "        #     baseline_model_new_h5.summary()\n",
        "        print (baseline_model_new_h5.evaluate(y_test, y_label))\n",
        "        \n",
        "        \n",
        "#         print ( baseline_model_new_h5.predict(preprocessor.transform(np.random.random([11,x_dim]))) )\n",
        "        batch_size = 10\n",
        "        s_i = np.random.choice(range(len(y_test)), batch_size)\n",
        "\n",
        "        y_predict = baseline_model_new_h5.predict(y_test[s_i])\n",
        "        print(\"______________________\")\n",
        "        \n",
        "        display(y_test[s_i])\n",
        "        display(y_label[s_i])\n",
        "        for i in range(10):\n",
        "            print(y_test[s_i][i], \" => \", np.round(y_predict[i]) , \" vs \", y_label[s_i][i])\n",
        "        \n",
        "            \n",
        "        x = y_predict[:,0] + y_predict[:, -1]\n",
        "        \n",
        "        print (np.sum(np.abs(x)) / len(x))\n",
        "        print(\"______________________\")\n",
        "\n",
        "    if 1:\n",
        "        tf.saved_model.save(baseline_model, \"./mm/1/\")   ## save a .pb file\n",
        "\n",
        "        baseline_model.save_weights('./mm/ckpt')\n",
        "        baseline_model_new_ckp = gen_model(x_dim, y_dim)\n",
        "        #     baseline_model_new_ckp.summary()\n",
        "        baseline_model_new_ckp.load_weights('./mm/ckpt')\n",
        "        \n",
        "        print (baseline_model_new_ckp.evaluate(y_test, y_label))\n",
        "        print (y_test.shape)\n",
        "        print (y_label.shape)\n",
        "        print()\n",
        "        baseline_model_new_ckp.summary()\n",
        "\n",
        "    print (\"- h5 networks filesize is : \" , get_mm_filesize(baseline_model.count_params()) , \" kbytes\")\n",
        "\n",
        "### lib_ end \n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_44 (Dense)             (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 25,410\n",
            "Trainable params: 25,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_44 (Dense)             (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 25,410\n",
            "Trainable params: 25,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1564064238\n",
            "1564064241\n",
            "dict_keys(['loss', 'mean_absolute_error', 'binary_crossentropy', 'val_loss', 'val_mean_absolute_error', 'val_binary_crossentropy']) \n",
            "\n",
            "(4, 7)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mean_absolute_error</th>\n",
              "      <th>binary_crossentropy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mean_absolute_error</th>\n",
              "      <th>val_binary_crossentropy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.419907</td>\n",
              "      <td>0.505262</td>\n",
              "      <td>-2.884889</td>\n",
              "      <td>0.308214</td>\n",
              "      <td>0.422968</td>\n",
              "      <td>-3.549881</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.260292</td>\n",
              "      <td>0.389561</td>\n",
              "      <td>-3.937944</td>\n",
              "      <td>0.220580</td>\n",
              "      <td>0.356776</td>\n",
              "      <td>-4.283643</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.189264</td>\n",
              "      <td>0.325112</td>\n",
              "      <td>-4.396674</td>\n",
              "      <td>0.160507</td>\n",
              "      <td>0.295449</td>\n",
              "      <td>-4.586597</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.147118</td>\n",
              "      <td>0.276882</td>\n",
              "      <td>-4.601456</td>\n",
              "      <td>0.133226</td>\n",
              "      <td>0.262208</td>\n",
              "      <td>-4.700403</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  mean_absolute_error  ...  val_binary_crossentropy  epoch\n",
              "0  0.419907             0.505262  ...                -3.549881      0\n",
              "1  0.260292             0.389561  ...                -4.283643      1\n",
              "2  0.189264             0.325112  ...                -4.586597      2\n",
              "3  0.147118             0.276882  ...                -4.700403      3\n",
              "\n",
              "[4 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 0s 83us/sample - loss: 0.1332 - mean_absolute_error: 0.2622 - binary_crossentropy: -4.7004\n",
            "[0.13322557322978973, 0.26220778, -4.700402]\n",
            "5000/5000 [==============================] - 0s 81us/sample - loss: 0.1332 - mean_absolute_error: 0.2622 - binary_crossentropy: -4.7004\n",
            "[0.13322557322978973, 0.26220778, -4.700402]\n",
            "______________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0.32406917, 0.27238176, 0.11911524],\n",
              "       [0.90419005, 0.10208939, 0.46258706],\n",
              "       [0.09526244, 0.66234923, 0.61020547],\n",
              "       [0.34592257, 0.55429569, 0.10587882],\n",
              "       [0.00764523, 0.03195949, 0.0494315 ],\n",
              "       [0.30630537, 0.44119367, 0.46140606],\n",
              "       [0.83774009, 0.47992459, 0.50510394],\n",
              "       [0.87715753, 0.34236202, 0.76920743],\n",
              "       [0.31446048, 0.54892229, 0.06464239],\n",
              "       [0.57966543, 0.3614562 , 0.69197782]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0., 2.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 2.],\n",
              "       [2., 0.],\n",
              "       [2., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 2.],\n",
              "       [2., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0.32406917 0.27238176 0.11911524]  =>  [0. 2.]  vs  [0. 2.]\n",
            "[0.90419005 0.10208939 0.46258706]  =>  [0. 1.]  vs  [0. 1.]\n",
            "[0.09526244 0.66234923 0.61020547]  =>  [1. 0.]  vs  [1. 0.]\n",
            "[0.34592257 0.55429569 0.10587882]  =>  [1. 2.]  vs  [1. 2.]\n",
            "[0.00764523 0.03195949 0.0494315 ]  =>  [1. 1.]  vs  [2. 0.]\n",
            "[0.30630537 0.44119367 0.46140606]  =>  [2. 0.]  vs  [2. 0.]\n",
            "[0.83774009 0.47992459 0.50510394]  =>  [0. 1.]  vs  [0. 1.]\n",
            "[0.87715753 0.34236202 0.76920743]  =>  [1. 1.]  vs  [0. 1.]\n",
            "[0.31446048 0.54892229 0.06464239]  =>  [1. 2.]  vs  [1. 2.]\n",
            "[0.57966543 0.3614562  0.69197782]  =>  [2. 1.]  vs  [2. 1.]\n",
            "2.0239227294921873\n",
            "______________________\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_48 (Dense)             (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 25,410\n",
            "Trainable params: 25,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "5000/5000 [==============================] - 0s 81us/sample - loss: 0.1332 - mean_absolute_error: 0.2622 - binary_crossentropy: -4.7004\n",
            "[0.13322557322978973, 0.26220778, -4.700402]\n",
            "(5000, 3)\n",
            "(5000, 2)\n",
            "\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_48 (Dense)             (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 25,410\n",
            "Trainable params: 25,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "- h5 networks filesize is :  331.75  kbytes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAFACAYAAACybXUeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ-REgovuCFi",
        "colab_type": "code",
        "outputId": "60b1645a-97d3-4a64-8f72-ba4cb1437a39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.preprocessing as prep \n",
        "from IPython.display import display\n",
        "\n",
        "### sub list ###\n",
        "\n",
        "def gen_train_label(rows, x_dim, y_dim):\n",
        "    x_train = np.random.random([rows,x_dim])\n",
        "    x_label = np.random.random([rows,y_dim])\n",
        "    x_label.fill(0.0)\n",
        "\n",
        "    for idx in range(rows):\n",
        "        e_ = x_train[idx]\n",
        "\n",
        "        e_c = ( (e_[0] * 1 + e_[-1] * 2) - 0.66 ) * 1.0\n",
        "#         e_c = e_[0] + e_[-1]\n",
        "        x_label[idx][0] = e_c\n",
        "        x_label[idx][-1] = -e_c + 0\n",
        "\n",
        "    return [x_train, x_label]\n",
        "\n",
        "def norm_x_y_data(X_train, X_test):\n",
        "    #import sklearn.preprocessing as prep \n",
        "    preprocessor = prep.StandardScaler().fit(X_train)\n",
        "    X_train = preprocessor.transform(X_train)\n",
        "    X_test = preprocessor.transform(X_test)\n",
        "    # X_train_R0=preprocessor.inverse_transform(X_test)    \n",
        "    return [X_train, X_test, preprocessor]\n",
        "\n",
        "def plot_history(histories, key='binary_crossentropy'):\n",
        "    plt.figure(figsize=(8,5))\n",
        "\n",
        "    for name, history in histories:\n",
        "        val = plt.plot(history.epoch, history.history['val_'+key], '--', label=name.title()+' Val')\n",
        "        plt.plot(history.epoch, history.history[key], color=val[0].get_color(), label=name.title()+' Train')\n",
        "\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(key.replace('_',' ').title())\n",
        "    plt.legend()\n",
        "\n",
        "    plt.xlim([0,max(history.epoch)])\n",
        "\n",
        "\n",
        "\n",
        "def show_predict(y_test, y_label, y_predict):\n",
        "    cnt_err = 0\n",
        "    for i in range(len(y_test)):\n",
        "        if np.argmax(y_label[i]) != np.argmax(y_predict[i]):\n",
        "            print (y_test[i])\n",
        "            print (y_label[i] , \" vs \" , y_predict[i])\n",
        "            e_ =  y_test[i]\n",
        "            print (\"- diff is :\" , np.abs(np.sqrt(e_[0] * e_[0] + e_[-1] * e_[-1]) - 0.66 ))\n",
        "            cnt_err += 1\n",
        "            print()\n",
        "    print(\"- cnt error is \", cnt_err)\n",
        "    print()\n",
        "\n",
        "def get_mm_filesize(param_num):\n",
        "    R0 = 33.9765625\n",
        "    each_size = 0.01171875\n",
        "    return R0 + param_num * each_size \n",
        "\n",
        "def gen_model(x_dim, y_dim):\n",
        "#     baseline_model.compile(optimizer='adam',\n",
        "#                        loss='binary_crossentropy',\n",
        "#                        metrics=['accuracy', 'binary_crossentropy'])    \n",
        "\n",
        "\n",
        "    baseline_model = keras.Sequential([\n",
        "    # `input_shape` is only required here so that `.summary` works.\n",
        "#         keras.layers.Dense(8, activation=tf.nn.relu, input_shape=(x_dim,)),\n",
        "        keras.layers.Dense(6, input_shape=(x_dim,)),\n",
        "         keras.layers.Dense(4, activation=\"linear\"),\n",
        "#         keras.layers.Dropout(0.2),\n",
        "#         keras.layers.Dense(y_dim, activation=tf.nn.sigmoid)\n",
        "         keras.layers.Dense(y_dim, activation=\"linear\")\n",
        "\n",
        "    ])\n",
        "    \n",
        "    \n",
        "#     baseline_model.summary()\n",
        "#     opt = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "    \n",
        "#     baseline_model.compile(\n",
        "#         optimizer=tf.keras.optimizers.Adam(),\n",
        "\n",
        "#                 loss=tf.keras.losses.binary_crossentropy,\n",
        "#                 metrics=['accuracy','binary_crossentropy'])\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.RMSprop(0.001/2)\n",
        "#     optimizer=tf.keras.optimizers.Adam(0.002)\n",
        "\n",
        "    baseline_model.compile(loss='mean_squared_error',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mean_absolute_error', 'binary_crossentropy'])    \n",
        "    \n",
        "    return baseline_model    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "#     !perl -e \"print time\"\n",
        "    preprocessor = None\n",
        "    import os\n",
        "    if not os.path.exists(\"./mm\"):\n",
        "        !mkdir  mm\n",
        "        !ls mm\n",
        "    \n",
        "    \n",
        "    rows = 10000\n",
        "    x_dim = 3\n",
        "    y_dim = 2    \n",
        "    flag_train = 1\n",
        "    \n",
        "    \n",
        "\n",
        "    key_acc = \"acc\"\n",
        "    \n",
        "    if \"WINDIR\" in os.environ :\n",
        "        key_acc = \"accuracy\"  # my windows   \n",
        "        \n",
        "    if \"HOME\" in os.environ and os.environ[\"HOME\"] == \"/home/bgi902\":\n",
        "        key_acc = \"accuracy\"\n",
        "    \n",
        "        \n",
        "\n",
        "    [x_train, x_label] = gen_train_label(rows, x_dim, y_dim)\n",
        "    [y_test, y_label] = gen_train_label( int(rows/2), x_dim, y_dim)\n",
        "    \n",
        "    \n",
        "    [x_train, y_test, preprocessor] = norm_x_y_data(x_train, y_test)\n",
        "    \n",
        "    \n",
        "    if flag_train:\n",
        "        baseline_model = gen_model(x_dim, y_dim)\n",
        "        baseline_model.summary()\n",
        "\n",
        "\n",
        "    #     early_stop = keras.callbacks.EarlyStopping(monitor=\"val_\" + key_acc,  patience=7)\n",
        "        !perl -e \"print time\"\n",
        "        print()\n",
        "        baseline_history = baseline_model.fit(x_train,\n",
        "                                          x_label,\n",
        "                                          epochs=10,\n",
        "                                          batch_size=200,\n",
        "                                          validation_data=(y_test, y_label),\n",
        "    #                                       callbacks=[early_stop],\n",
        "                                          verbose=0)    \n",
        "\n",
        "        !perl -e \"print time\"\n",
        "        print()\n",
        "\n",
        "\n",
        "        plot_history( [ ('baseline', baseline_history) ], key=\"loss\") # may be \"acc\" if gpu\n",
        "    #     plot_history( [ ('baseline', baseline_history) ], key=\"binary_crossentropy\")\n",
        "\n",
        "        print(baseline_history.history.keys(), \"\\n\")\n",
        "\n",
        "        # history to DF\n",
        "        baseline_history_ = pd.DataFrame(baseline_history.history)\n",
        "        baseline_history_['epoch'] = baseline_history.epoch\n",
        "        print(baseline_history_.shape)\n",
        "        print()\n",
        "        display(baseline_history_.tail())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #     show_predict(y_test[s_i], y_label[s_i], y_predict)\n",
        "\n",
        "        print (baseline_model.evaluate(y_test, y_label))\n",
        "\n",
        "\n",
        "    if 1:\n",
        "        if flag_train:\n",
        "            baseline_model.save('./mm/h5.h5')\n",
        "            \n",
        "        baseline_model_new_h5 = tf.keras.models.load_model('./mm/h5.h5')\n",
        "        #     baseline_model_new_h5.summary()\n",
        "        print (baseline_model_new_h5.evaluate(y_test, y_label))\n",
        "        \n",
        "        \n",
        "#         print ( baseline_model_new_h5.predict(preprocessor.transform(np.random.random([11,x_dim]))) )\n",
        "        batch_size = 10\n",
        "        s_i = np.random.choice(range(len(y_test)), batch_size)\n",
        "\n",
        "        y_predict = baseline_model_new_h5.predict(y_test[s_i])\n",
        "        print(\"______________________\")\n",
        "        \n",
        "#         display(y_test[s_i])\n",
        "#         display(y_label[s_i])\n",
        "        for i in range(10):\n",
        "            print(y_test[s_i][i], \" => \", y_predict[i] , \" vs \", y_label[s_i][i])\n",
        "        \n",
        "            \n",
        "        x = y_predict[:,0] + y_predict[:, -1]\n",
        "        \n",
        "        print (np.sum(np.abs(x)) / len(x))\n",
        "        print(\"______________________\")\n",
        "\n",
        "    if 0:\n",
        "        baseline_model.save_weights('./mm/ckpt')\n",
        "        baseline_model_new_ckp = gen_model(x_dim, y_dim)\n",
        "        #     baseline_model_new_ckp.summary()\n",
        "        baseline_model_new_ckp.load_weights('./mm/ckpt')\n",
        "        print (baseline_model_new_ckp.evaluate(y_test, y_label))\n",
        "        baseline_model_new_ckp.summary()\n",
        "\n",
        "    print (\"- h5 networks filesize is : \" , get_mm_filesize(baseline_model.count_params()) , \" kbytes\")\n",
        "\n",
        "### lib_ end \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 6)                 24        \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4)                 28        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 10        \n",
            "=================================================================\n",
            "Total params: 62\n",
            "Trainable params: 62\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1555828547\n",
            "1555828564\n",
            "dict_keys(['loss', 'mean_absolute_error', 'binary_crossentropy', 'val_loss', 'val_mean_absolute_error', 'val_binary_crossentropy']) \n",
            "\n",
            "(10, 7)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mean_absolute_error</th>\n",
              "      <th>binary_crossentropy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mean_absolute_error</th>\n",
              "      <th>val_binary_crossentropy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.304295</td>\n",
              "      <td>0.452117</td>\n",
              "      <td>-7.150898</td>\n",
              "      <td>0.225649</td>\n",
              "      <td>0.392880</td>\n",
              "      <td>-7.823065</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.155195</td>\n",
              "      <td>0.325533</td>\n",
              "      <td>-7.931726</td>\n",
              "      <td>0.102338</td>\n",
              "      <td>0.268212</td>\n",
              "      <td>-8.351917</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.062553</td>\n",
              "      <td>0.207565</td>\n",
              "      <td>-8.315254</td>\n",
              "      <td>0.033277</td>\n",
              "      <td>0.153337</td>\n",
              "      <td>-8.640584</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.015469</td>\n",
              "      <td>0.099196</td>\n",
              "      <td>-8.528850</td>\n",
              "      <td>0.003561</td>\n",
              "      <td>0.048838</td>\n",
              "      <td>-8.759858</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.000772</td>\n",
              "      <td>0.016819</td>\n",
              "      <td>-8.586223</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.002325</td>\n",
              "      <td>-8.770650</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  mean_absolute_error  binary_crossentropy  val_loss  \\\n",
              "5  0.304295             0.452117            -7.150898  0.225649   \n",
              "6  0.155195             0.325533            -7.931726  0.102338   \n",
              "7  0.062553             0.207565            -8.315254  0.033277   \n",
              "8  0.015469             0.099196            -8.528850  0.003561   \n",
              "9  0.000772             0.016819            -8.586223  0.000008   \n",
              "\n",
              "   val_mean_absolute_error  val_binary_crossentropy  epoch  \n",
              "5                 0.392880                -7.823065      5  \n",
              "6                 0.268212                -8.351917      6  \n",
              "7                 0.153337                -8.640584      7  \n",
              "8                 0.048838                -8.759858      8  \n",
              "9                 0.002325                -8.770650      9  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 0s 22us/sample - loss: 8.1484e-06 - mean_absolute_error: 0.0023 - binary_crossentropy: -8.7707\n",
            "[8.148354959848802e-06, 0.0023246892, -8.770651]\n",
            "5000/5000 [==============================] - 0s 30us/sample - loss: 8.1484e-06 - mean_absolute_error: 0.0023 - binary_crossentropy: -8.7707\n",
            "[8.148354959848802e-06, 0.0023246892, -8.770651]\n",
            "______________________\n",
            "[-0.95834912 -1.59358479  1.30836139]  =>  [ 1.3187398 -1.3206425]  vs  [ 1.32044606 -1.32044606]\n",
            "[-1.56110295 -1.36699219  1.17375678]  =>  [ 1.0655887 -1.068581 ]  vs  [ 1.06810723 -1.06810723]\n",
            "[ 1.0124769  -0.99498412 -1.3228312 ]  =>  [ 0.3735069  -0.37202588]  vs  [ 0.37007473 -0.37007473]\n",
            "[ 0.91167206 -0.00740947 -0.68782699]  =>  [ 0.7087125  -0.70718145]  vs  [ 0.70796612 -0.70796612]\n",
            "[1.34457604 1.39383896 1.69986099]  =>  [ 2.2088675 -2.2060184]  vs  [ 2.21357387 -2.21357387]\n",
            "[-1.21492063 -0.62518609  1.3038216 ]  =>  [ 1.2399758 -1.2421987]  vs  [ 1.24353142 -1.24353142]\n",
            "[-1.21053928  1.30367922  1.09228678]  =>  [ 1.1161393 -1.1180782]  vs  [ 1.12251726 -1.12251726]\n",
            "[ 0.35714479  0.94076034 -1.70120642]  =>  [-0.03826171  0.03879373]  vs  [-0.0384056  0.0384056]\n",
            "[-1.23797205 -1.60209395  1.15687964]  =>  [ 1.1501514 -1.1525885]  vs  [ 1.15191356 -1.15191356]\n",
            "[-1.60223475 -0.52076032 -0.22248697]  =>  [ 0.24724373 -0.25035572]  vs  [ 0.24906528 -0.24906528]\n",
            "0.0020999118685722353\n",
            "______________________\n",
            "- h5 networks filesize is :  34.703125  kbytes\n",
            "CPU times: user 3.36 s, sys: 228 ms, total: 3.59 s\n",
            "Wall time: 33.3 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfsAAAFACAYAAAC7htVkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n75xzzsXc/wG6rktf5ewVrAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbKhg0Wifd_j",
        "colab_type": "code",
        "outputId": "e9f0566a-4d80-4d3c-fb9f-eeecf57cf8ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1067
        }
      },
      "source": [
        "%%time \n",
        "\n",
        "### classify ### \n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.preprocessing as prep \n",
        "from IPython.display import display\n",
        "\n",
        "### lib_\n",
        "\n",
        "\n",
        "\n",
        "def plot_history(histories, key='binary_crossentropy'):\n",
        "    plt.figure(figsize=(8,5))\n",
        "\n",
        "    for name, history in histories:\n",
        "        val = plt.plot(history.epoch, history.history['val_'+key], '--', label=name.title()+' Val')\n",
        "        plt.plot(history.epoch, history.history[key], color=val[0].get_color(), label=name.title()+' Train')\n",
        "\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(key.replace('_',' ').title())\n",
        "    plt.legend()\n",
        "\n",
        "    plt.xlim([0,max(history.epoch)])\n",
        "\n",
        "def norm_x_y_data(X_train, X_test):\n",
        "    #import sklearn.preprocessing as prep \n",
        "    preprocessor = prep.StandardScaler().fit(X_train)\n",
        "    X_train = preprocessor.transform(X_train)\n",
        "    X_test = preprocessor.transform(X_test)\n",
        "    # X_train_R0=preprocessor.inverse_transform(X_test)    \n",
        "    return [X_train, X_test]\n",
        "\n",
        "def show_predict(y_test, y_label, y_predict):\n",
        "    cnt_err = 0\n",
        "    for i in range(len(y_test)):\n",
        "        if np.argmax(y_label[i]) != np.argmax(y_predict[i]):\n",
        "            print (y_test[i])\n",
        "            print (y_label[i] , \" vs \" , y_predict[i])\n",
        "            e_ =  y_test[i]\n",
        "            print (\"- diff is :\" , np.abs(np.sqrt(e_[0] * e_[0] + e_[-1] * e_[-1]) - 0.66))\n",
        "            cnt_err += 1\n",
        "            print()\n",
        "    print(\"- cnt error is \", cnt_err)\n",
        "    print()\n",
        "\n",
        "def get_mm_filesize(param_num):\n",
        "    R0 = 33.9765625\n",
        "    each_size = 0.01171875\n",
        "    return R0 + param_num * each_size \n",
        "\n",
        "def gen_model(x_dim, y_dim):\n",
        "#     baseline_model.compile(optimizer='adam',\n",
        "#                        loss='binary_crossentropy',\n",
        "#                        metrics=['accuracy', 'binary_crossentropy'])    \n",
        "\n",
        "\n",
        "    baseline_model = keras.Sequential([\n",
        "    # `input_shape` is only required here so that `.summary` works.\n",
        "        keras.layers.Dense(16, activation=tf.nn.relu, input_shape=(x_dim,)),\n",
        "        keras.layers.Dense(8, activation=tf.nn.relu),\n",
        "    #     keras.layers.Dropout(0.2),\n",
        "        keras.layers.Dense(y_dim, activation=tf.nn.sigmoid) ])\n",
        "    \n",
        "    \n",
        "#     baseline_model.summary()\n",
        "#     opt = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "    \n",
        "    baseline_model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "\n",
        "                loss=tf.keras.losses.binary_crossentropy,\n",
        "                metrics=['accuracy','binary_crossentropy'])\n",
        "    \n",
        "    \n",
        "    return baseline_model    \n",
        "\n",
        "def gen_train_label(rows, x_dim, y_dim):\n",
        "    x_train = np.random.random([rows,x_dim])\n",
        "    x_label = np.random.random([rows,y_dim])\n",
        "    x_label.fill(0.0)\n",
        "\n",
        "    for idx in range(rows):\n",
        "        e_ = x_train[idx]\n",
        "\n",
        "        e_c = (np.sqrt(e_[0] * e_[0] + e_[-1] * e_[-1]) > 0.66) * 1.0\n",
        "        x_label[idx][int(e_c)] = 1.0\n",
        "\n",
        "    return [x_train, x_label]\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "#     !perl -e \"print time\"\n",
        "    import os\n",
        "    if not os.path.exists(\"./mm\"):\n",
        "        !mkdir  mm\n",
        "        !ls mm\n",
        "    \n",
        "    \n",
        "    rows = 10000\n",
        "    x_dim = 10\n",
        "    y_dim = 2    \n",
        "    \n",
        "\n",
        "    key_acc = \"acc\"\n",
        "    \n",
        "    if \"WINDIR\" in os.environ :\n",
        "        key_acc = \"accuracy\"  # my windows   \n",
        "        \n",
        "#     if \"HOME\" in os.environ and os.environ[\"HOME\"] == \"/home/bgi902\":\n",
        "#         key_acc = \"accuracy\"\n",
        "    \n",
        "        \n",
        "\n",
        "    [x_train, x_label] = gen_train_label(rows, x_dim, y_dim)\n",
        "    [y_test, y_label] = gen_train_label( int(rows/2), x_dim, y_dim)\n",
        "#     [x_train, y_test] = norm_x_y_data(x_train, y_test)\n",
        "    baseline_model = gen_model(x_dim, y_dim)\n",
        "    \n",
        "\n",
        "    early_stop = keras.callbacks.EarlyStopping(monitor=\"val_\" + key_acc,  patience=7)\n",
        "    !perl -e \"print time\"\n",
        "    print()\n",
        "    baseline_history = baseline_model.fit(x_train,\n",
        "                                      x_label,\n",
        "                                      epochs=300,\n",
        "                                      batch_size=1000,\n",
        "                                      validation_data=(y_test, y_label),\n",
        "                                      callbacks=[early_stop],\n",
        "                                      verbose=0)    \n",
        "    \n",
        "    !perl -e \"print time\"\n",
        "    print()\n",
        "\n",
        "    plot_history( [ ('baseline', baseline_history) ], key=key_acc) # may be \"acc\" if gpu\n",
        "    plot_history( [ ('baseline', baseline_history) ], key=\"binary_crossentropy\")\n",
        "    \n",
        "    print(baseline_history.history.keys(), \"\\n\")\n",
        "\n",
        "    # history to DF\n",
        "    baseline_history_ = pd.DataFrame(baseline_history.history)\n",
        "    baseline_history_['epoch'] = baseline_history.epoch\n",
        "    print(baseline_history_.shape)\n",
        "    print()\n",
        "    display(baseline_history_.tail())\n",
        "    \n",
        "    \n",
        "    batch_size = 1000\n",
        "    s_i = np.random.choice(range(len(y_test)), batch_size)\n",
        "    y_predict = baseline_model.predict(y_test[s_i])\n",
        "#     show_predict(y_test[s_i], y_label[s_i], y_predict)\n",
        "    \n",
        "    print (baseline_model.evaluate(y_test, y_label))\n",
        "    \n",
        "\n",
        "    if 1:\n",
        "        baseline_model.save('./mm/h5.h5')\n",
        "        baseline_model_new_h5 = tf.keras.models.load_model('./mm/h5.h5')\n",
        "        #     baseline_model_new_h5.summary()\n",
        "        print (baseline_model_new_h5.evaluate(y_test, y_label))\n",
        "\n",
        "    if 0:\n",
        "        baseline_model.save_weights('./mm/ckpt')\n",
        "        baseline_model_new_ckp = gen_model(x_dim, y_dim)\n",
        "        #     baseline_model_new_ckp.summary()\n",
        "        baseline_model_new_ckp.load_weights('./mm/ckpt')\n",
        "        print (baseline_model_new_ckp.evaluate(y_test, y_label))\n",
        "        baseline_model_new_ckp.summary()\n",
        "\n",
        "    print (\"- h5 networks filesize is : \" , get_mm_filesize(baseline_model.count_params()) , \" kbytes\")\n",
        "\n",
        "### lib_ end\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1555640767\n",
            "1555640777\n",
            "dict_keys(['loss', 'acc', 'binary_crossentropy', 'val_loss', 'val_acc', 'val_binary_crossentropy']) \n",
            "\n",
            "(196, 7)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>acc</th>\n",
              "      <th>binary_crossentropy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_acc</th>\n",
              "      <th>val_binary_crossentropy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>0.040094</td>\n",
              "      <td>0.98805</td>\n",
              "      <td>0.040094</td>\n",
              "      <td>0.035027</td>\n",
              "      <td>0.9920</td>\n",
              "      <td>0.035027</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>0.040437</td>\n",
              "      <td>0.98780</td>\n",
              "      <td>0.040437</td>\n",
              "      <td>0.034645</td>\n",
              "      <td>0.9921</td>\n",
              "      <td>0.034645</td>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>0.039813</td>\n",
              "      <td>0.98745</td>\n",
              "      <td>0.039813</td>\n",
              "      <td>0.034599</td>\n",
              "      <td>0.9925</td>\n",
              "      <td>0.034599</td>\n",
              "      <td>193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>0.039450</td>\n",
              "      <td>0.98810</td>\n",
              "      <td>0.039450</td>\n",
              "      <td>0.034484</td>\n",
              "      <td>0.9913</td>\n",
              "      <td>0.034484</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>0.039548</td>\n",
              "      <td>0.98770</td>\n",
              "      <td>0.039548</td>\n",
              "      <td>0.034046</td>\n",
              "      <td>0.9925</td>\n",
              "      <td>0.034046</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss      acc  binary_crossentropy  val_loss  val_acc  \\\n",
              "191  0.040094  0.98805             0.040094  0.035027   0.9920   \n",
              "192  0.040437  0.98780             0.040437  0.034645   0.9921   \n",
              "193  0.039813  0.98745             0.039813  0.034599   0.9925   \n",
              "194  0.039450  0.98810             0.039450  0.034484   0.9913   \n",
              "195  0.039548  0.98770             0.039548  0.034046   0.9925   \n",
              "\n",
              "     val_binary_crossentropy  epoch  \n",
              "191                 0.035027    191  \n",
              "192                 0.034645    192  \n",
              "193                 0.034599    193  \n",
              "194                 0.034484    194  \n",
              "195                 0.034046    195  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 0s 23us/sample - loss: 0.0340 - acc: 0.9925 - binary_crossentropy: 0.0340\n",
            "[0.034046190930902956, 0.9925, 0.034046188]\n",
            "5000/5000 [==============================] - 0s 43us/sample - loss: 0.0340 - acc: 0.9925 - binary_crossentropy: 0.0340\n",
            "[0.034046190930902956, 0.9925, 0.034046188]\n",
            "- h5 networks filesize is :  37.84375  kbytes\n",
            "CPU times: user 13.3 s, sys: 480 ms, total: 13.8 s\n",
            "Wall time: 14.1 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFACAYAAAClT+XXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzczMMuGmbmZmlon/A7ZomcRjRXyYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFACAYAAAClT+XXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOncjhBfWWT8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZIG_VdiyW_P",
        "colab_type": "code",
        "outputId": "85a6f88d-102b-4576-ae1d-fd2b6838318a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1655
        }
      },
      "source": [
        "%%time\n",
        "# jd add\n",
        "\n",
        "\n",
        "\n",
        "#   import list\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf  # tf version = 2.0.0-alpha. with keras\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.preprocessing as prep \n",
        "#\n",
        "\n",
        "np.mat(\"1,2,3;1,5,6\")\n",
        "\n",
        "\n",
        "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
        "                      na_values = \"?\", comment='\\t',\n",
        "                      sep=\" \", skipinitialspace=True)\n",
        "\n",
        "dataset = raw_dataset.copy()\n",
        "dataset.isna().sum()\n",
        "dataset = dataset.dropna()\n",
        "dataset.isna().sum()\n",
        "dataset.tail(11)\n",
        "origin = dataset.pop('Origin')\n",
        "\n",
        "dataset['USA'] = (origin == 1)*1.0\n",
        "dataset['Europe'] = (origin == 2)*1.0\n",
        "dataset['Japan'] = (origin == 3)*1.0\n",
        "dataset.tail()\n",
        "\n",
        "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
        "train_dataset.shape\n",
        "test_dataset = dataset.drop(train_dataset.index)\n",
        "test_dataset.shape\n",
        "\n",
        "# see the table's dist\n",
        "# sns.pairplot(train_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]], diag_kind=\"kde\")\n",
        "\n",
        "train_stats = train_dataset.describe()\n",
        "train_stats.pop(\"MPG\")\n",
        "\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats\n",
        "\n",
        "\n",
        "train_labels = train_dataset.pop('MPG')\n",
        "test_labels = test_dataset.pop('MPG')\n",
        "test_labels.tail()\n",
        "\n",
        "\n",
        "preprocessor = prep.StandardScaler().fit(train_dataset.values)\n",
        "mycl = train_dataset.columns\n",
        "np_normed_train_data = preprocessor.transform(train_dataset.values)\n",
        "np_normed_test_data = preprocessor.transform(test_dataset.values)\n",
        "\n",
        "normed_train_data = pd.DataFrame(np_normed_train_data, columns=mycl)\n",
        "normed_test_data = pd.DataFrame(np_normed_test_data, columns=mycl)\n",
        "\n",
        "# print(normed_train_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "\n",
        "# normed_train_data = norm(train_dataset)\n",
        "# normed_train_data.tail()[\"Cylinders\"].loc[281]   # 0.307\n",
        "# normed_test_data = norm(test_dataset)\n",
        "\n",
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(64, activation=tf.nn.relu, input_shape=[len(train_dataset.keys())]),\n",
        "    layers.Dense(64, activation=tf.nn.relu),\n",
        "    layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mean_squared_error',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        " # print(model.batch_size)\n",
        "  print()\n",
        "  return model\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "model.summary()\n",
        "normed_train_data.tail()\n",
        "\n",
        "\n",
        "# Display training progress by printing a single dot for each completed epoch\n",
        "class PrintDot(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 100 == 0: print('')\n",
        "    print('.', end='')\n",
        "\n",
        "EPOCHS = 300\n",
        "\n",
        "history = model.fit(\n",
        "  normed_train_data, train_labels,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
        "  callbacks=[PrintDot()])\n",
        "\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "print(hist.shape)\n",
        "\n",
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [MPG]')\n",
        "  plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,5])\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error [$MPG^2$]')\n",
        "  plt.plot(hist['epoch'], hist['mean_squared_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,20])\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# plot_history(history)\n",
        "# -----------------------------\n",
        "# -----------------------------\n",
        "\n",
        "model_early_stop = build_model()\n",
        "\n",
        "# The patience parameter is the amount of epochs to check for improvement\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=11)\n",
        "\n",
        "history_early_stop = model_early_stop.fit(normed_train_data, train_labels, epochs=EPOCHS,\n",
        "                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])\n",
        "\n",
        "# plot_history(history_early_stop)\n",
        "\n",
        "hist_early_stop = pd.DataFrame(history_early_stop.history)\n",
        "hist_early_stop['epoch'] = history_early_stop.epoch\n",
        "print(hist_early_stop.shape)\n",
        "\n",
        "\n",
        "loss, mae, mse = model_early_stop.evaluate(normed_test_data, test_labels, verbose=0)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))\n",
        "print(\"Testing set Mean Std Error: {:5.2f} MPG\".format(mse))\n",
        "\n",
        "test_predictions = model_early_stop.predict(normed_test_data).flatten()\n",
        "# print(test_predictions)\n",
        "\n",
        "print(type(test_labels))\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values [MPG]')\n",
        "plt.ylabel('Predictions [MPG]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "_ = plt.plot([-100, 100], [-100, 100])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "error = test_predictions - test_labels\n",
        "if 0:\n",
        "    plt.hist(error, bins = 25)\n",
        "    plt.xlabel(\"Prediction Error [MPG]\")\n",
        "    _ = plt.ylabel(\"Count\")\n",
        "\n",
        "# Save weights to a TensorFlow Checkpoint file\n",
        "model_early_stop.save_weights('./mm/my_model')\n",
        "\n",
        "\n",
        "# Restore the model's state,\n",
        "# this requires a model with the same architecture.\n",
        "reload_model = build_model()\n",
        "\n",
        "reload_model.load_weights('./mm/my_model')\n",
        "reload_model.summary()\n",
        "\n",
        "reload_test_predictions = reload_model.predict(normed_test_data).flatten()\n",
        "# print(test_predictions)\n",
        "print (reload_test_predictions == test_predictions)\n",
        "\n",
        "\n",
        "model_early_stop.save('./mm/h5.h5')\n",
        "h5_reload_model = tf.keras.models.load_model('./mm/h5.h5')\n",
        "h5_reload_model.summary()\n",
        "h5_reload_test_predictions = h5_reload_model.predict(normed_test_data).flatten()\n",
        "# print(test_predictions)\n",
        "print (h5_reload_test_predictions == test_predictions)\n",
        "\n",
        "# !date \"+%Y%m%d_%H%M%S\"\n",
        "# jd end"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\n",
            "32768/30286 [================================] - 0s 1us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 64)                640       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 4,865\n",
            "Trainable params: 4,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "....................................................................................................\n",
            "....................................................................................................\n",
            "....................................................................................................(300, 7)\n",
            "\n",
            "\n",
            "..............................................................................(78, 7)\n",
            "Testing set Mean Abs Error:  1.76 MPG\n",
            "Testing set Mean Std Error:  5.31 MPG\n",
            "<class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAEKCAYAAAD0Ait6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.RMSprop object at 0x7f7c5e0f9080>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
            "\n",
            "Consider using a TensorFlow optimizer from `tf.train`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 64)                640       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 4,865\n",
            "Trainable params: 4,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 64)                640       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 4,865\n",
            "Trainable params: 4,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True]\n",
            "CPU times: user 15.6 s, sys: 702 ms, total: 16.3 s\n",
            "Wall time: 14.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}